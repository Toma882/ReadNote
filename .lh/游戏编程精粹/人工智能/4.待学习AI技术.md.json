{
    "sourceFile": "游戏编程精粹/人工智能/4.待学习AI技术.md",
    "activeCommit": 0,
    "commits": [
        {
            "activePatchIndex": 8,
            "patches": [
                {
                    "date": 1765967845606,
                    "content": "Index: \n===================================================================\n--- \n+++ \n"
                },
                {
                    "date": 1765968019500,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -189,8 +189,99 @@\n   - 多单位密集移动场景\r\n   - 需要容错性的AI系统\r\n - **Unity工具**：Unity NavMesh + Physics（基础支持）、需要自己实现高级方法\r\n \r\n+## 游戏编程精粹4\r\n+\r\n+### 4.3 非玩家角色决策:处理随机问题 ⭐⭐⭐\r\n+\r\n+- **项目已有**：可能有基础决策系统\r\n+- **掌握程度**：部分掌握，有决策系统使用经验，但可以学习处理随机问题的决策系统\r\n+- **学习价值**：学习使用动态规划算法处理NPC决策中的随机问题\r\n+- **学习内容**：\r\n+  - 动态规划算法\r\n+  - 处理随机问题的决策方法\r\n+  - 代码实现\r\n+  - 优化技巧\r\n+  - DP算法的其他应用\r\n+- **应用场景**：\r\n+  - NPC决策系统\r\n+  - 随机环境下的决策\r\n+  - 动态规划在游戏AI中的应用\r\n+- **Unity工具**：需要自己实现\r\n+- **参考价值**：理解动态规划在AI决策中的应用\r\n+\r\n+### 4.4 一个基于效用的面向对象决策架构 ⭐⭐⭐\r\n+\r\n+- **项目已有**：可能有基础决策系统\r\n+- **掌握程度**：部分掌握，有决策系统使用经验，但可以学习基于效用的决策架构\r\n+- **学习价值**：学习基于效用的面向对象决策架构，实现更灵活的决策系统\r\n+- **学习内容**：\r\n+  - 决策树\r\n+  - 基于对象的更好的体系结构\r\n+  - 期望值计算\r\n+  - 其他的决策准则\r\n+- **应用场景**：\r\n+  - NPC决策系统\r\n+  - 基于效用的决策\r\n+  - 面向对象的AI架构\r\n+- **Unity工具**：需要自己实现\r\n+- **参考价值**：理解效用决策架构的设计思想\r\n+\r\n+### 4.5 一个分布式推理投票架构 ⭐⭐⭐\r\n+\r\n+- **项目已有**：可能有基础推理系统\r\n+- **掌握程度**：部分掌握，有推理系统使用经验，但可以学习分布式推理投票架构\r\n+- **学习价值**：学习分布式推理投票架构，实现多系统协作的决策\r\n+- **学习内容**：\r\n+  - 分布式推理\r\n+  - 操纵仲裁者(Steering Arbiter)范例\r\n+  - 选择投票空间\r\n+- **应用场景**：\r\n+  - 多系统协作决策\r\n+  - 分布式AI系统\r\n+  - 投票机制在AI中的应用\r\n+- **Unity工具**：需要自己实现\r\n+- **参考价值**：理解分布式推理和投票机制\r\n+\r\n+### 4.6 吸引子和排斥子 ⭐⭐⭐\r\n+\r\n+- **项目已有**：可能有基础移动系统\r\n+- **掌握程度**：部分掌握，有移动系统使用经验，但可以学习吸引子和排斥子系统\r\n+- **学习价值**：学习吸引子和排斥子系统，实现更自然的AI移动行为\r\n+- **学习内容**：\r\n+  - 合力计算\r\n+  - 引力曲线\r\n+  - 吸引曲线的和\r\n+  - 对应于特定配对的特定曲线\r\n+  - 动态曲线\r\n+  - 点、线、面\r\n+  - AI控制的层次\r\n+  - 动画系统的交互\r\n+  - 移动(Steering)\r\n+- **应用场景**：\r\n+  - AI移动行为\r\n+  - 与Steering Behaviors相关\r\n+  - 自然移动系统\r\n+- **Unity工具**：需要自己实现\r\n+- **参考价值**：理解吸引子和排斥子在AI移动中的应用\r\n+\r\n+### 4.7 高级RTS游戏造墙算法 ⭐⭐⭐\r\n+\r\n+- **项目已有**：可能有基础RTS系统\r\n+- **掌握程度**：部分掌握，有RTS开发经验，但可以学习高级造墙算法\r\n+- **学习价值**：学习高级RTS游戏造墙算法，实现智能建筑系统\r\n+- **学习内容**：\r\n+  - 算法实现\r\n+  - 算法改进\r\n+  - 输出链表的形式\r\n+- **应用场景**：\r\n+  - RTS游戏\r\n+  - 智能建筑系统\r\n+  - 自动造墙\r\n+- **Unity工具**：需要自己实现\r\n+- **参考价值**：理解RTS特定算法的实现思路\r\n+\r\n ## 总结\r\n \r\n **待学习的AI技术**：\r\n 1. ⭐⭐⭐ **Steering Behaviors**：定向行为系统，AI移动行为基础\r\n@@ -202,8 +293,13 @@\n 7. ⭐⭐⭐ **地形推理**：战术分析系统\r\n 8. ⭐⭐⭐ **可视点寻径**：路径优化技术\r\n 9. ⭐⭐⭐ **区域游览**：寻径模式扩展\r\n 10. ⭐⭐⭐ **寻径与碰撞**：高级关系处理方法\r\n+11. ⭐⭐⭐ **NPC决策处理随机问题**：动态规划算法\r\n+12. ⭐⭐⭐ **基于效用的决策架构**：面向对象决策系统\r\n+13. ⭐⭐⭐ **分布式推理投票架构**：多系统协作决策\r\n+14. ⭐⭐⭐ **吸引子和排斥子**：自然移动系统\r\n+15. ⭐⭐⭐ **RTS造墙算法**：智能建筑系统\r\n \r\n **学习建议**：\r\n - 按需学习，根据项目需求决定是否实现\r\n - 可以基于现有系统（网格系统、寻路系统）实现\r\n"
                },
                {
                    "date": 1765968625554,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -280,8 +280,85 @@\n   - 自动造墙\r\n - **Unity工具**：需要自己实现\r\n - **参考价值**：理解RTS特定算法的实现思路\r\n \r\n+## 游戏编程精粹5\r\n+\r\n+### 3.2 使用人工势场实现快速目标评级 ⭐⭐⭐\r\n+\r\n+- **项目已有**：可能有基础AI系统\r\n+- **掌握程度**：部分掌握，有AI开发经验，但可以学习人工势场系统\r\n+- **学习价值**：学习使用人工势场实现快速目标评级，实现智能目标选择\r\n+- **学习内容**：\r\n+  - 基本思想\r\n+  - 公式\r\n+  - 势值函数的评估\r\n+  - 可视化\r\n+  - 方向场的应用\r\n+  - 多维扩展\r\n+- **应用场景**：\r\n+  - 目标选择系统\r\n+  - 快速目标评级\r\n+  - 智能决策系统\r\n+- **Unity工具**：需要自己实现\r\n+- **参考价值**：理解人工势场在AI决策中的应用\r\n+\r\n+### 3.3 利用Lanchester损耗模型来预测战斗结果 ⭐⭐⭐\r\n+\r\n+- **项目已有**：可能有基础战斗系统\r\n+- **掌握程度**：部分掌握，有战斗系统使用经验，但可以学习战斗预测模型\r\n+- **学习价值**：学习利用Lanchester损耗模型来预测战斗结果，实现智能战斗评估\r\n+- **学习内容**：\r\n+  - 概述\r\n+  - 场景1:全体混战\r\n+  - 场景2:狭窄的石阶\r\n+  - 场景3:炮战\r\n+  - 场景4:关底Boss\r\n+  - 关于战斗力的再讨论\r\n+  - 局限性\r\n+- **应用场景**：\r\n+  - 战斗预测系统\r\n+  - 战斗结果评估\r\n+  - 战术决策系统\r\n+- **Unity工具**：需要自己实现\r\n+- **参考价值**：理解战斗预测模型在AI决策中的应用\r\n+\r\n+### 3.4 为游戏AI实现一个实用的智能规划系统 ⭐⭐⭐\r\n+\r\n+- **项目已有**：可能有基础决策系统\r\n+- **掌握程度**：部分掌握，有决策系统使用经验，但可以学习智能规划系统\r\n+- **学习价值**：学习为游戏AI实现一个实用的智能规划系统，实现长期目标规划\r\n+- **学习内容**：\r\n+  - 规划系统的框架\r\n+  - 规划域\r\n+  - 一个多主体规划器的例子\r\n+  - 规划的搜索\r\n+  - 几个应用问题\r\n+  - 优化\r\n+- **应用场景**：\r\n+  - 长期目标规划\r\n+  - 多主体协作\r\n+  - 智能规划系统\r\n+- **Unity工具**：需要自己实现\r\n+- **参考价值**：理解智能规划系统在游戏AI中的应用\r\n+\r\n+### 3.8 实现最小重新规划开销的先进寻路算法:动态A*(D*)算法 ⭐⭐⭐\r\n+\r\n+- **项目已有**：A*寻路算法实现\r\n+- **掌握程度**：部分掌握，有A*寻路经验，但可以学习动态A*算法\r\n+- **学习价值**：学习动态A*(D*)算法，实现最小重新规划开销的寻路系统\r\n+- **学习内容**：\r\n+  - D*算法\r\n+  - D*算法的实现细节\r\n+  - 实例\r\n+  - 在游戏中又如何呢?\r\n+- **应用场景**：\r\n+  - 动态环境寻路\r\n+  - 需要频繁重新规划的寻路\r\n+  - 最小开销重新规划\r\n+- **Unity工具**：Unity NavMesh（基础支持）、需要自己实现D*算法\r\n+- **参考价值**：理解动态寻路算法在游戏中的应用\r\n+\r\n ## 总结\r\n \r\n **待学习的AI技术**：\r\n 1. ⭐⭐⭐ **Steering Behaviors**：定向行为系统，AI移动行为基础\r\n"
                },
                {
                    "date": 1765968633690,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -375,8 +375,12 @@\n 12. ⭐⭐⭐ **基于效用的决策架构**：面向对象决策系统\r\n 13. ⭐⭐⭐ **分布式推理投票架构**：多系统协作决策\r\n 14. ⭐⭐⭐ **吸引子和排斥子**：自然移动系统\r\n 15. ⭐⭐⭐ **RTS造墙算法**：智能建筑系统\r\n+16. ⭐⭐⭐ **人工势场**：快速目标评级系统\r\n+17. ⭐⭐⭐ **Lanchester损耗模型**：战斗结果预测系统\r\n+18. ⭐⭐⭐ **智能规划系统**：长期目标规划系统\r\n+19. ⭐⭐⭐ **动态A*(D*)算法**：最小重新规划开销的寻路算法\r\n \r\n **学习建议**：\r\n - 按需学习，根据项目需求决定是否实现\r\n - 可以基于现有系统（网格系统、寻路系统）实现\r\n"
                },
                {
                    "date": 1765968850278,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -357,8 +357,112 @@\n   - 最小开销重新规划\r\n - **Unity工具**：Unity NavMesh（基础支持）、需要自己实现D*算法\r\n - **参考价值**：理解动态寻路算法在游戏中的应用\r\n \r\n+## 游戏编程精粹6\r\n+\r\n+### 3.2 独立非玩家角色合作行为的实现 ⭐⭐⭐\r\n+\r\n+- **项目已有**：可能有基础NPC系统\r\n+- **掌握程度**：部分掌握，有NPC开发经验，但可以学习NPC合作行为系统\r\n+- **学习价值**：学习独立非玩家角色合作行为的实现，实现NPC协作系统\r\n+- **学习内容**：\r\n+  - 可能的解决方案\r\n+  - 非玩家角色的结构\r\n+  - 合作的机制\r\n+  - 例子:合作寻找玩家\r\n+- **应用场景**：\r\n+  - NPC协作系统\r\n+  - 团队AI行为\r\n+  - 多NPC协调\r\n+- **Unity工具**：需要自己实现\r\n+- **参考价值**：理解NPC合作行为的实现思路\r\n+\r\n+### 3.3 针对游戏的基于行为的机器人架构 ⭐⭐⭐\r\n+\r\n+- **项目已有**：可能有基础AI系统\r\n+- **掌握程度**：部分掌握，有AI开发经验，但可以学习基于行为的架构\r\n+- **学习价值**：学习针对游戏的基于行为的机器人架构，实现行为驱动AI\r\n+- **学习内容**：\r\n+  - 包容体结构\r\n+  - 扩展的行为网络\r\n+  - 讨论\r\n+- **应用场景**：\r\n+  - 行为驱动AI\r\n+  - 基于行为的机器人\r\n+  - 行为网络系统\r\n+- **Unity工具**：需要自己实现\r\n+- **参考价值**：理解基于行为的AI架构设计\r\n+\r\n+### 3.4 使用模糊感知器、有限状态自动机和扩展的行为网络构建目标驱动的机器人 ⭐⭐⭐\r\n+\r\n+- **项目已有**：有限状态机（项目已有完整FSM系统）\r\n+- **掌握程度**：部分掌握，有FSM使用经验，但可以学习模糊感知器+行为网络组合\r\n+- **学习价值**：学习使用模糊感知器、FSM和扩展的行为网络构建目标驱动的机器人\r\n+- **学习内容**：\r\n+  - 扩展的行为网络设计\r\n+  - 层次模糊感知器\r\n+  - 有限状态自动机行为模块\r\n+- **应用场景**：\r\n+  - 目标驱动AI\r\n+  - 模糊感知器应用\r\n+  - 行为网络系统\r\n+- **Unity工具**：需要自己实现，可以基于现有FSM系统扩展\r\n+- **参考价值**：理解模糊感知器、FSM和行为网络的组合应用\r\n+\r\n+### 3.5 一个目标驱动的虚幻竞技场游戏角色程序 ⭐⭐⭐\r\n+\r\n+- **项目已有**：可能有基础AI系统\r\n+- **掌握程度**：部分掌握，有AI开发经验，但可以学习目标驱动的代理系统\r\n+- **学习价值**：学习使用扩展的行为网络制作目标驱动的具有个性的代理\r\n+- **学习内容**：\r\n+  - 扩展的行为网络\r\n+  - 行为选择的质量\r\n+  - 个性设计\r\n+- **应用场景**：\r\n+  - 目标驱动AI\r\n+  - 具有个性的代理\r\n+  - 行为网络系统\r\n+- **Unity工具**：需要自己实现\r\n+- **参考价值**：理解目标驱动代理和个性设计\r\n+\r\n+### 3.6 用支持向量机为短期记忆建模 ⭐⭐⭐\r\n+\r\n+- **项目已有**：可能有基础AI系统\r\n+- **掌握程度**：部分掌握，有AI开发经验，但可以学习支持向量机（SVM）应用\r\n+- **学习价值**：学习用支持向量机为短期记忆建模，实现AI记忆系统\r\n+- **学习内容**：\r\n+  - 支持向量机简介\r\n+  - 短期记忆模型化\r\n+  - CPU的消耗限制\r\n+- **应用场景**：\r\n+  - AI记忆系统\r\n+  - 短期记忆建模\r\n+  - 机器学习应用\r\n+- **Unity工具**：需要自己实现\r\n+- **参考价值**：理解支持向量机在游戏AI中的应用\r\n+\r\n+### 3.7 使用战力值评估模型进行战争役分析 ⭐⭐⭐\r\n+\r\n+- **项目已有**：可能有基础战斗系统\r\n+- **掌握程度**：部分掌握，有战斗系统使用经验，但可以学习战力值评估模型\r\n+- **学习价值**：学习使用战力值评估模型进行战争役分析，实现战斗评估系统\r\n+- **学习内容**：\r\n+  - 基本公式\r\n+  - 计算兵力\r\n+  - 计算潜在兵力\r\n+  - 为武器效力进行建模\r\n+  - 获得一个理论上的战争结局\r\n+  - 关于CEV\r\n+  - 一个QJM系统的例子\r\n+  - 局限性\r\n+- **应用场景**：\r\n+  - 战斗评估系统\r\n+  - 战争役分析\r\n+  - 战力值评估\r\n+- **Unity工具**：需要自己实现\r\n+- **参考价值**：理解战力值评估模型在游戏中的应用\r\n+\r\n ## 总结\r\n \r\n **待学习的AI技术**：\r\n 1. ⭐⭐⭐ **Steering Behaviors**：定向行为系统，AI移动行为基础\r\n"
                },
                {
                    "date": 1765968863085,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -483,8 +483,14 @@\n 16. ⭐⭐⭐ **人工势场**：快速目标评级系统\r\n 17. ⭐⭐⭐ **Lanchester损耗模型**：战斗结果预测系统\r\n 18. ⭐⭐⭐ **智能规划系统**：长期目标规划系统\r\n 19. ⭐⭐⭐ **动态A*(D*)算法**：最小重新规划开销的寻路算法\r\n+20. ⭐⭐⭐ **NPC合作行为**：独立非玩家角色合作行为的实现\r\n+21. ⭐⭐⭐ **基于行为的架构**：针对游戏的基于行为的机器人架构\r\n+22. ⭐⭐⭐ **模糊感知器+行为网络**：目标驱动的机器人构建\r\n+23. ⭐⭐⭐ **目标驱动代理**：具有个性的目标驱动代理\r\n+24. ⭐⭐⭐ **支持向量机**：用支持向量机为短期记忆建模\r\n+25. ⭐⭐⭐ **战力值评估模型**：使用战力值评估模型进行战争役分析\r\n \r\n **学习建议**：\r\n - 按需学习，根据项目需求决定是否实现\r\n - 可以基于现有系统（网格系统、寻路系统）实现\r\n"
                },
                {
                    "date": 1765968932204,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -461,8 +461,65 @@\n   - 战力值评估\r\n - **Unity工具**：需要自己实现\r\n - **参考价值**：理解战力值评估模型在游戏中的应用\r\n \r\n+## 游戏编程精粹7\r\n+\r\n+### 3.1 用行为克隆创建有趣的代理 ⭐⭐⭐\r\n+\r\n+- **项目已有**：可能有基础AI系统\r\n+- **掌握程度**：部分掌握，有AI开发经验，但可以学习行为克隆技术\r\n+- **学习价值**：学习用行为克隆创建有趣的代理，实现机器学习驱动的AI\r\n+- **学习内容**：\r\n+  - 实例:The Demo Game\r\n+  - 行为克隆技术\r\n+  - 机器学习应用\r\n+- **应用场景**：\r\n+  - 机器学习驱动的AI\r\n+  - 行为克隆系统\r\n+  - 有趣的代理创建\r\n+- **Unity工具**：\r\n+  - Unity ML-Agents（机器学习，可能支持行为克隆）\r\n+  - ⚠️ **需要自己实现**：行为克隆系统\r\n+- **参考价值**：理解行为克隆在游戏AI中的应用\r\n+\r\n+### 3.4 有关态度的一切:为意见、声望和NPC个性构建单元 ⭐⭐⭐\r\n+\r\n+- **项目已有**：可能有基础NPC系统\r\n+- **掌握程度**：部分掌握，有NPC开发经验，但可以学习NPC个性系统\r\n+- **学习价值**：学习为意见、声望和NPC个性构建单元，实现复杂的NPC个性系统\r\n+- **学习内容**：\r\n+  - 简介\r\n+  - 态度\r\n+  - 态度里有什么\r\n+  - 复杂的态度对象\r\n+  - 态度和行为\r\n+  - 说服和影响\r\n+  - 态度的社会交换\r\n+  - 另一个例子\r\n+  - 注意事项和结论\r\n+- **应用场景**：\r\n+  - NPC个性系统\r\n+  - 意见和声望系统\r\n+  - 复杂的态度建模\r\n+- **Unity工具**：需要自己实现\r\n+- **参考价值**：理解NPC个性系统在游戏中的应用\r\n+\r\n+### 3.6 面向目标的计划合并 ⭐⭐⭐\r\n+\r\n+- **项目已有**：可能有基础规划系统\r\n+- **掌握程度**：部分掌握，有规划系统使用经验，但可以学习目标计划合并\r\n+- **学习价值**：学习面向目标的计划合并，实现多目标协调规划\r\n+- **学习内容**：\r\n+  - 回顾面向目标的计划系统\r\n+  - 用于面向目标计划的计划合并\r\n+- **应用场景**：\r\n+  - 多目标协调规划\r\n+  - 计划合并系统\r\n+  - 目标驱动规划\r\n+- **Unity工具**：需要自己实现\r\n+- **参考价值**：理解目标计划合并在游戏AI中的应用\r\n+\r\n ## 总结\r\n \r\n **待学习的AI技术**：\r\n 1. ⭐⭐⭐ **Steering Behaviors**：定向行为系统，AI移动行为基础\r\n"
                },
                {
                    "date": 1765968997092,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -546,8 +546,11 @@\n 22. ⭐⭐⭐ **模糊感知器+行为网络**：目标驱动的机器人构建\r\n 23. ⭐⭐⭐ **目标驱动代理**：具有个性的目标驱动代理\r\n 24. ⭐⭐⭐ **支持向量机**：用支持向量机为短期记忆建模\r\n 25. ⭐⭐⭐ **战力值评估模型**：使用战力值评估模型进行战争役分析\r\n+26. ⭐⭐⭐ **行为克隆**：用行为克隆创建有趣的代理\r\n+27. ⭐⭐⭐ **NPC个性系统**：为意见、声望和NPC个性构建单元\r\n+28. ⭐⭐⭐ **目标计划合并**：面向目标的计划合并\r\n \r\n **学习建议**：\r\n - 按需学习，根据项目需求决定是否实现\r\n - 可以基于现有系统（网格系统、寻路系统）实现\r\n"
                },
                {
                    "date": 1765971303755,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -507,9 +507,9 @@\n ### 3.6 面向目标的计划合并 ⭐⭐⭐\r\n \r\n - **项目已有**：可能有基础规划系统\r\n - **掌握程度**：部分掌握，有规划系统使用经验，但可以学习目标计划合并\r\n-- **学习价值**：学习面向目标的计划合并，实现多目标协调规划\r\n+- **学习价值**：学习面向目标的计划合并，实现多目标协调规划        ，                                  \r\n - **学习内容**：\r\n   - 回顾面向目标的计划系统\r\n   - 用于面向目标计划的计划合并\r\n - **应用场景**：\r\n"
                }
            ],
            "date": 1765967845606,
            "name": "Commit-0",
            "content": "# 待学习AI技术（⭐⭐⭐）\r\n\r\n> 本文档整合了《游戏编程精粹》第1-7卷中项目部分掌握需要补充完善的AI技术。\r\n\r\n## 游戏编程精粹1\r\n\r\n### 5. Steering Behaviors（定向行为系统） ⭐⭐⭐\r\n\r\n- **项目已有**：可能有基础移动系统\r\n- **掌握程度**：部分掌握，有移动系统使用经验，但可以学习Steering Behaviors系统\r\n- **学习价值**：学习Reynolds提出的基础行为系统，实现各种移动行为\r\n- **学习内容**：\r\n  - Seek（寻找目标）\r\n  - Flee（逃离目标）\r\n  - Arrive（到达目标，带减速）\r\n  - Pursue（追逐移动目标）\r\n  - Evade（躲避移动目标）\r\n  - Align（对齐朝向）\r\n  - VelocityMatch（速度匹配）\r\n  - Wander（漫游）\r\n  - AvoidWall/AvoidAgent（避障）\r\n- **应用场景**：\r\n  - AI移动行为\r\n  - 群体行为基础\r\n  - 动态避障系统\r\n- **Unity工具**：需要自己实现\r\n- **参考代码**：`ReadNote/游戏编程精粹/1/代码/SteeringBehaviors(定向行为系统).md`\r\n\r\n### 5. Flocking（群集行为） ⭐⭐⭐\r\n\r\n- **项目已有**：可能有基础移动系统\r\n- **掌握程度**：部分掌握，有移动系统使用经验，但可以学习Flocking群集行为\r\n- **学习价值**：学习Craig Reynolds提出的分布式行为模型，模拟鸟群、鱼群等生物群体行为\r\n- **学习内容**：\r\n  - 四个基本规则（Reynolds规则）：\r\n    1. 分离（Separation）：避免与邻近个体过于接近\r\n    2. 对齐（Alignment）：与邻近个体的平均航向和速度对齐\r\n    3. 聚集（Cohesion）：向邻近个体的平均位置移动\r\n    4. 躲避（Avoidance）：避免撞上局部区域内的障碍或敌人\r\n  - 无状态特性\r\n  - 矢量累积机制\r\n  - 性能优化（空间分区、邻居限制）\r\n- **应用场景**：\r\n  - 群体AI行为\r\n  - 鸟群、鱼群模拟\r\n  - RTS/RPG中的群体动画\r\n- **Unity工具**：需要自己实现\r\n- **参考代码**：`ReadNote/游戏编程精粹/1/代码/Flocking群集行为.md`\r\n\r\n### 5. 模糊逻辑（Fuzzy Logic） ⭐⭐⭐\r\n\r\n- **项目已有**：可能有基础决策系统\r\n- **掌握程度**：部分掌握，有决策系统使用经验，但可以学习模糊逻辑决策系统\r\n- **学习价值**：学习处理不确定性和模糊性的数学方法，实现平滑的AI决策\r\n- **学习内容**：\r\n  - 模糊集合和隶属度函数\r\n  - 模糊推理（Fuzzy Inference）：\r\n    1. 模糊化（Fuzzification）\r\n    2. 规则评估（Rule Evaluation）\r\n    3. 聚合（Aggregation）\r\n    4. 去模糊化（Defuzzification）\r\n  - 典型隶属度函数（三角形、梯形、S形）\r\n  - 模糊逻辑运算（AND、OR、NOT）\r\n- **应用场景**：\r\n  - AI决策系统\r\n  - NPC行为选择\r\n  - 难度调整\r\n  - 资源管理\r\n- **Unity工具**：需要自己实现\r\n- **参考代码**：`ReadNote/游戏编程精粹/1/代码/模糊逻辑(FuzzyLogic).md`\r\n\r\n### 5. 神经网络（Neural Networks） ⭐⭐⭐\r\n\r\n- **项目已有**：可能有基础AI系统\r\n- **掌握程度**：部分掌握，有AI开发经验，但可以学习神经网络系统\r\n- **学习价值**：学习模拟生物神经系统的计算模型，实现复杂的非线性映射\r\n- **学习内容**：\r\n  - 神经单元（Neuron）结构\r\n  - 激活函数（Sigmoid、ReLU、Tanh）\r\n  - 多层神经网络\r\n  - Hebbian学习规则\r\n  - 前向传播和反向传播\r\n- **应用场景**：\r\n  - AI决策\r\n  - 行为预测\r\n  - 难度调整\r\n  - NPC行为学习\r\n- **Unity工具**：Unity ML-Agents（机器学习）、需要自己实现基础神经网络\r\n- **参考代码**：`ReadNote/游戏编程精粹/1/代码/神经网络(Neural Networks).md`\r\n\r\n### 5. 影响力地图（Influence Map） ⭐⭐⭐\r\n\r\n- **项目已有**：可能有基础网格系统（GridSystem）\r\n- **掌握程度**：部分掌握，有网格系统使用经验，但可以学习影响力地图系统\r\n- **学习价值**：学习用于AI决策的地图系统，表示地图上各区域的重要性\r\n- **学习内容**：\r\n  - 影响力传播算法\r\n  - 合意值计算（Desirability）\r\n  - 地形考虑\r\n  - 3D环境应用\r\n  - 影响力衰减（线性衰减或指数衰减）\r\n- **应用场景**：\r\n  - RTS游戏中的战略决策\r\n  - 单位部署\r\n  - 资源点选择\r\n  - 战术位置评估\r\n- **Unity工具**：需要自己实现，可以基于现有的网格系统和范围查找策略实现\r\n- **参考代码**：`ReadNote/游戏编程精粹/1/代码/影响力地图(InfluenceMap).md`\r\n\r\n### 5. 策略评估技术 ⭐⭐⭐\r\n\r\n- **项目已有**：可能有基础决策系统\r\n- **掌握程度**：部分掌握，有决策系统使用经验，但可以学习策略评估技术\r\n- **学习价值**：学习资源分配树、依存图等策略评估技术\r\n- **学习内容**：\r\n  - 资源分配树\r\n  - 依存图\r\n  - 策略决策\r\n  - 经济规划\r\n- **应用场景**：\r\n  - RTS游戏的经济规划\r\n  - 资源分配\r\n  - 策略类游戏\r\n- **Unity工具**：需要自己实现\r\n- **参考代码**：`ReadNote/游戏编程精粹/1/代码/策略评估技术(StrategyEvaluation).md`\r\n\r\n### 5. 地形推理 ⭐⭐⭐\r\n\r\n- **项目已有**：可能有基础地形系统（EBattleTerrain地形类型枚举）\r\n- **掌握程度**：部分掌握，有地形使用经验，但可以学习地形推理技术\r\n- **学习价值**：学习中继点（Waypoint）、战术分析等地形推理技术\r\n- **学习内容**：\r\n  - 中继点系统\r\n  - 战术分析\r\n  - 地形表示\r\n  - 从经验中学习\r\n- **应用场景**：\r\n  - 战术位置评估\r\n  - 防御点识别\r\n  - 进攻路线规划\r\n- **Unity工具**：Unity NavMesh（基础支持）、需要自己实现高级功能\r\n- **参考代码**：`ReadNote/游戏编程精粹/1/代码/地形推理(TerrainReasoning).md`\r\n\r\n### 5. 可视点寻径（Points-of-Visibility Pathfinding） ⭐⭐⭐\r\n\r\n- **项目已有**：A*寻路算法实现\r\n- **掌握程度**：部分掌握，有A*寻路经验，但可以学习可视点寻径优化技术\r\n- **学习价值**：学习可视点寻径优化技术，用于优化路径查找\r\n- **学习内容**：\r\n  - 可视点寻径算法\r\n  - 存储到每个点的最短路径\r\n  - 轮廓区\r\n  - 空间分区系统\r\n- **应用场景**：\r\n  - 路径优化\r\n  - 大规模寻径系统\r\n  - 作为A*算法的优化技术\r\n- **Unity工具**：Unity NavMesh（基础支持）、需要自己实现高级优化\r\n- **参考代码**：`ReadNote/游戏编程精粹/1/代码/可视点寻径(PointsOfVisibility).md`\r\n\r\n## 游戏编程精粹3\r\n\r\n### 3.9 区域游览（寻径模式扩展） ⭐⭐⭐\r\n\r\n- **项目已有**：A*寻路算法实现和Unity NavMesh系统\r\n- **掌握程度**：部分掌握，有基础寻径经验，但可以学习区域游览模式\r\n- **学习价值**：学习寻径模式扩展，实现区域游览功能\r\n- **学习内容**：\r\n  - 区域游览的概念\r\n  - 寻径模式扩展\r\n  - 区域识别和遍历\r\n- **应用场景**：\r\n  - 巡逻系统\r\n  - 区域探索\r\n  - 寻径模式扩展\r\n- **Unity工具**：Unity NavMesh（基础支持）、需要自己实现区域游览\r\n\r\n### 3.8 在寻径与碰撞之间选择一种关系（高级方法） ⭐⭐⭐\r\n\r\n- **项目已有**：Unity NavMesh系统和物理碰撞系统\r\n- **掌握程度**：部分掌握，有基础寻径与碰撞经验，但可以学习三种关系处理方法\r\n- **学习价值**：学习寻径与碰撞的三种关系处理方法，实现更精确的移动控制\r\n- **学习内容**：\r\n  - 方法1：具有容错性的AI（容错寻径）\r\n  - 方法2：在无障碍空间一个子集内的寻径（受限寻径）\r\n  - 方法3：使用寻径器本身处理人物碰撞（寻径器碰撞处理）\r\n- **应用场景**：\r\n  - 需要精确碰撞控制的游戏\r\n  - 多单位密集移动场景\r\n  - 需要容错性的AI系统\r\n- **Unity工具**：Unity NavMesh + Physics（基础支持）、需要自己实现高级方法\r\n\r\n## 总结\r\n\r\n**待学习的AI技术**：\r\n1. ⭐⭐⭐ **Steering Behaviors**：定向行为系统，AI移动行为基础\r\n2. ⭐⭐⭐ **Flocking**：群集行为，群体AI行为\r\n3. ⭐⭐⭐ **模糊逻辑**：模糊决策系统\r\n4. ⭐⭐⭐ **神经网络**：AI学习系统\r\n5. ⭐⭐⭐ **影响力地图**：战略决策系统\r\n6. ⭐⭐⭐ **策略评估技术**：资源分配和决策\r\n7. ⭐⭐⭐ **地形推理**：战术分析系统\r\n8. ⭐⭐⭐ **可视点寻径**：路径优化技术\r\n9. ⭐⭐⭐ **区域游览**：寻径模式扩展\r\n10. ⭐⭐⭐ **寻径与碰撞**：高级关系处理方法\r\n\r\n**学习建议**：\r\n- 按需学习，根据项目需求决定是否实现\r\n- 可以基于现有系统（网格系统、寻路系统）实现\r\n- 参考代码示例，理解原理后实现\r\n\r\n"
        }
    ]
}