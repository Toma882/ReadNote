{
    "sourceFile": "游戏编程精粹/人工智能/4.待学习AI技术.md",
    "activeCommit": 0,
    "commits": [
        {
            "activePatchIndex": 10,
            "patches": [
                {
                    "date": 1765967845606,
                    "content": "Index: \n===================================================================\n--- \n+++ \n"
                },
                {
                    "date": 1765968019500,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -189,8 +189,99 @@\n   - 多单位密集移动场景\r\n   - 需要容错性的AI系统\r\n - **Unity工具**：Unity NavMesh + Physics（基础支持）、需要自己实现高级方法\r\n \r\n+## 游戏编程精粹4\r\n+\r\n+### 4.3 非玩家角色决策:处理随机问题 ⭐⭐⭐\r\n+\r\n+- **项目已有**：可能有基础决策系统\r\n+- **掌握程度**：部分掌握，有决策系统使用经验，但可以学习处理随机问题的决策系统\r\n+- **学习价值**：学习使用动态规划算法处理NPC决策中的随机问题\r\n+- **学习内容**：\r\n+  - 动态规划算法\r\n+  - 处理随机问题的决策方法\r\n+  - 代码实现\r\n+  - 优化技巧\r\n+  - DP算法的其他应用\r\n+- **应用场景**：\r\n+  - NPC决策系统\r\n+  - 随机环境下的决策\r\n+  - 动态规划在游戏AI中的应用\r\n+- **Unity工具**：需要自己实现\r\n+- **参考价值**：理解动态规划在AI决策中的应用\r\n+\r\n+### 4.4 一个基于效用的面向对象决策架构 ⭐⭐⭐\r\n+\r\n+- **项目已有**：可能有基础决策系统\r\n+- **掌握程度**：部分掌握，有决策系统使用经验，但可以学习基于效用的决策架构\r\n+- **学习价值**：学习基于效用的面向对象决策架构，实现更灵活的决策系统\r\n+- **学习内容**：\r\n+  - 决策树\r\n+  - 基于对象的更好的体系结构\r\n+  - 期望值计算\r\n+  - 其他的决策准则\r\n+- **应用场景**：\r\n+  - NPC决策系统\r\n+  - 基于效用的决策\r\n+  - 面向对象的AI架构\r\n+- **Unity工具**：需要自己实现\r\n+- **参考价值**：理解效用决策架构的设计思想\r\n+\r\n+### 4.5 一个分布式推理投票架构 ⭐⭐⭐\r\n+\r\n+- **项目已有**：可能有基础推理系统\r\n+- **掌握程度**：部分掌握，有推理系统使用经验，但可以学习分布式推理投票架构\r\n+- **学习价值**：学习分布式推理投票架构，实现多系统协作的决策\r\n+- **学习内容**：\r\n+  - 分布式推理\r\n+  - 操纵仲裁者(Steering Arbiter)范例\r\n+  - 选择投票空间\r\n+- **应用场景**：\r\n+  - 多系统协作决策\r\n+  - 分布式AI系统\r\n+  - 投票机制在AI中的应用\r\n+- **Unity工具**：需要自己实现\r\n+- **参考价值**：理解分布式推理和投票机制\r\n+\r\n+### 4.6 吸引子和排斥子 ⭐⭐⭐\r\n+\r\n+- **项目已有**：可能有基础移动系统\r\n+- **掌握程度**：部分掌握，有移动系统使用经验，但可以学习吸引子和排斥子系统\r\n+- **学习价值**：学习吸引子和排斥子系统，实现更自然的AI移动行为\r\n+- **学习内容**：\r\n+  - 合力计算\r\n+  - 引力曲线\r\n+  - 吸引曲线的和\r\n+  - 对应于特定配对的特定曲线\r\n+  - 动态曲线\r\n+  - 点、线、面\r\n+  - AI控制的层次\r\n+  - 动画系统的交互\r\n+  - 移动(Steering)\r\n+- **应用场景**：\r\n+  - AI移动行为\r\n+  - 与Steering Behaviors相关\r\n+  - 自然移动系统\r\n+- **Unity工具**：需要自己实现\r\n+- **参考价值**：理解吸引子和排斥子在AI移动中的应用\r\n+\r\n+### 4.7 高级RTS游戏造墙算法 ⭐⭐⭐\r\n+\r\n+- **项目已有**：可能有基础RTS系统\r\n+- **掌握程度**：部分掌握，有RTS开发经验，但可以学习高级造墙算法\r\n+- **学习价值**：学习高级RTS游戏造墙算法，实现智能建筑系统\r\n+- **学习内容**：\r\n+  - 算法实现\r\n+  - 算法改进\r\n+  - 输出链表的形式\r\n+- **应用场景**：\r\n+  - RTS游戏\r\n+  - 智能建筑系统\r\n+  - 自动造墙\r\n+- **Unity工具**：需要自己实现\r\n+- **参考价值**：理解RTS特定算法的实现思路\r\n+\r\n ## 总结\r\n \r\n **待学习的AI技术**：\r\n 1. ⭐⭐⭐ **Steering Behaviors**：定向行为系统，AI移动行为基础\r\n@@ -202,8 +293,13 @@\n 7. ⭐⭐⭐ **地形推理**：战术分析系统\r\n 8. ⭐⭐⭐ **可视点寻径**：路径优化技术\r\n 9. ⭐⭐⭐ **区域游览**：寻径模式扩展\r\n 10. ⭐⭐⭐ **寻径与碰撞**：高级关系处理方法\r\n+11. ⭐⭐⭐ **NPC决策处理随机问题**：动态规划算法\r\n+12. ⭐⭐⭐ **基于效用的决策架构**：面向对象决策系统\r\n+13. ⭐⭐⭐ **分布式推理投票架构**：多系统协作决策\r\n+14. ⭐⭐⭐ **吸引子和排斥子**：自然移动系统\r\n+15. ⭐⭐⭐ **RTS造墙算法**：智能建筑系统\r\n \r\n **学习建议**：\r\n - 按需学习，根据项目需求决定是否实现\r\n - 可以基于现有系统（网格系统、寻路系统）实现\r\n"
                },
                {
                    "date": 1765968625554,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -280,8 +280,85 @@\n   - 自动造墙\r\n - **Unity工具**：需要自己实现\r\n - **参考价值**：理解RTS特定算法的实现思路\r\n \r\n+## 游戏编程精粹5\r\n+\r\n+### 3.2 使用人工势场实现快速目标评级 ⭐⭐⭐\r\n+\r\n+- **项目已有**：可能有基础AI系统\r\n+- **掌握程度**：部分掌握，有AI开发经验，但可以学习人工势场系统\r\n+- **学习价值**：学习使用人工势场实现快速目标评级，实现智能目标选择\r\n+- **学习内容**：\r\n+  - 基本思想\r\n+  - 公式\r\n+  - 势值函数的评估\r\n+  - 可视化\r\n+  - 方向场的应用\r\n+  - 多维扩展\r\n+- **应用场景**：\r\n+  - 目标选择系统\r\n+  - 快速目标评级\r\n+  - 智能决策系统\r\n+- **Unity工具**：需要自己实现\r\n+- **参考价值**：理解人工势场在AI决策中的应用\r\n+\r\n+### 3.3 利用Lanchester损耗模型来预测战斗结果 ⭐⭐⭐\r\n+\r\n+- **项目已有**：可能有基础战斗系统\r\n+- **掌握程度**：部分掌握，有战斗系统使用经验，但可以学习战斗预测模型\r\n+- **学习价值**：学习利用Lanchester损耗模型来预测战斗结果，实现智能战斗评估\r\n+- **学习内容**：\r\n+  - 概述\r\n+  - 场景1:全体混战\r\n+  - 场景2:狭窄的石阶\r\n+  - 场景3:炮战\r\n+  - 场景4:关底Boss\r\n+  - 关于战斗力的再讨论\r\n+  - 局限性\r\n+- **应用场景**：\r\n+  - 战斗预测系统\r\n+  - 战斗结果评估\r\n+  - 战术决策系统\r\n+- **Unity工具**：需要自己实现\r\n+- **参考价值**：理解战斗预测模型在AI决策中的应用\r\n+\r\n+### 3.4 为游戏AI实现一个实用的智能规划系统 ⭐⭐⭐\r\n+\r\n+- **项目已有**：可能有基础决策系统\r\n+- **掌握程度**：部分掌握，有决策系统使用经验，但可以学习智能规划系统\r\n+- **学习价值**：学习为游戏AI实现一个实用的智能规划系统，实现长期目标规划\r\n+- **学习内容**：\r\n+  - 规划系统的框架\r\n+  - 规划域\r\n+  - 一个多主体规划器的例子\r\n+  - 规划的搜索\r\n+  - 几个应用问题\r\n+  - 优化\r\n+- **应用场景**：\r\n+  - 长期目标规划\r\n+  - 多主体协作\r\n+  - 智能规划系统\r\n+- **Unity工具**：需要自己实现\r\n+- **参考价值**：理解智能规划系统在游戏AI中的应用\r\n+\r\n+### 3.8 实现最小重新规划开销的先进寻路算法:动态A*(D*)算法 ⭐⭐⭐\r\n+\r\n+- **项目已有**：A*寻路算法实现\r\n+- **掌握程度**：部分掌握，有A*寻路经验，但可以学习动态A*算法\r\n+- **学习价值**：学习动态A*(D*)算法，实现最小重新规划开销的寻路系统\r\n+- **学习内容**：\r\n+  - D*算法\r\n+  - D*算法的实现细节\r\n+  - 实例\r\n+  - 在游戏中又如何呢?\r\n+- **应用场景**：\r\n+  - 动态环境寻路\r\n+  - 需要频繁重新规划的寻路\r\n+  - 最小开销重新规划\r\n+- **Unity工具**：Unity NavMesh（基础支持）、需要自己实现D*算法\r\n+- **参考价值**：理解动态寻路算法在游戏中的应用\r\n+\r\n ## 总结\r\n \r\n **待学习的AI技术**：\r\n 1. ⭐⭐⭐ **Steering Behaviors**：定向行为系统，AI移动行为基础\r\n"
                },
                {
                    "date": 1765968633690,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -375,8 +375,12 @@\n 12. ⭐⭐⭐ **基于效用的决策架构**：面向对象决策系统\r\n 13. ⭐⭐⭐ **分布式推理投票架构**：多系统协作决策\r\n 14. ⭐⭐⭐ **吸引子和排斥子**：自然移动系统\r\n 15. ⭐⭐⭐ **RTS造墙算法**：智能建筑系统\r\n+16. ⭐⭐⭐ **人工势场**：快速目标评级系统\r\n+17. ⭐⭐⭐ **Lanchester损耗模型**：战斗结果预测系统\r\n+18. ⭐⭐⭐ **智能规划系统**：长期目标规划系统\r\n+19. ⭐⭐⭐ **动态A*(D*)算法**：最小重新规划开销的寻路算法\r\n \r\n **学习建议**：\r\n - 按需学习，根据项目需求决定是否实现\r\n - 可以基于现有系统（网格系统、寻路系统）实现\r\n"
                },
                {
                    "date": 1765968850278,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -357,8 +357,112 @@\n   - 最小开销重新规划\r\n - **Unity工具**：Unity NavMesh（基础支持）、需要自己实现D*算法\r\n - **参考价值**：理解动态寻路算法在游戏中的应用\r\n \r\n+## 游戏编程精粹6\r\n+\r\n+### 3.2 独立非玩家角色合作行为的实现 ⭐⭐⭐\r\n+\r\n+- **项目已有**：可能有基础NPC系统\r\n+- **掌握程度**：部分掌握，有NPC开发经验，但可以学习NPC合作行为系统\r\n+- **学习价值**：学习独立非玩家角色合作行为的实现，实现NPC协作系统\r\n+- **学习内容**：\r\n+  - 可能的解决方案\r\n+  - 非玩家角色的结构\r\n+  - 合作的机制\r\n+  - 例子:合作寻找玩家\r\n+- **应用场景**：\r\n+  - NPC协作系统\r\n+  - 团队AI行为\r\n+  - 多NPC协调\r\n+- **Unity工具**：需要自己实现\r\n+- **参考价值**：理解NPC合作行为的实现思路\r\n+\r\n+### 3.3 针对游戏的基于行为的机器人架构 ⭐⭐⭐\r\n+\r\n+- **项目已有**：可能有基础AI系统\r\n+- **掌握程度**：部分掌握，有AI开发经验，但可以学习基于行为的架构\r\n+- **学习价值**：学习针对游戏的基于行为的机器人架构，实现行为驱动AI\r\n+- **学习内容**：\r\n+  - 包容体结构\r\n+  - 扩展的行为网络\r\n+  - 讨论\r\n+- **应用场景**：\r\n+  - 行为驱动AI\r\n+  - 基于行为的机器人\r\n+  - 行为网络系统\r\n+- **Unity工具**：需要自己实现\r\n+- **参考价值**：理解基于行为的AI架构设计\r\n+\r\n+### 3.4 使用模糊感知器、有限状态自动机和扩展的行为网络构建目标驱动的机器人 ⭐⭐⭐\r\n+\r\n+- **项目已有**：有限状态机（项目已有完整FSM系统）\r\n+- **掌握程度**：部分掌握，有FSM使用经验，但可以学习模糊感知器+行为网络组合\r\n+- **学习价值**：学习使用模糊感知器、FSM和扩展的行为网络构建目标驱动的机器人\r\n+- **学习内容**：\r\n+  - 扩展的行为网络设计\r\n+  - 层次模糊感知器\r\n+  - 有限状态自动机行为模块\r\n+- **应用场景**：\r\n+  - 目标驱动AI\r\n+  - 模糊感知器应用\r\n+  - 行为网络系统\r\n+- **Unity工具**：需要自己实现，可以基于现有FSM系统扩展\r\n+- **参考价值**：理解模糊感知器、FSM和行为网络的组合应用\r\n+\r\n+### 3.5 一个目标驱动的虚幻竞技场游戏角色程序 ⭐⭐⭐\r\n+\r\n+- **项目已有**：可能有基础AI系统\r\n+- **掌握程度**：部分掌握，有AI开发经验，但可以学习目标驱动的代理系统\r\n+- **学习价值**：学习使用扩展的行为网络制作目标驱动的具有个性的代理\r\n+- **学习内容**：\r\n+  - 扩展的行为网络\r\n+  - 行为选择的质量\r\n+  - 个性设计\r\n+- **应用场景**：\r\n+  - 目标驱动AI\r\n+  - 具有个性的代理\r\n+  - 行为网络系统\r\n+- **Unity工具**：需要自己实现\r\n+- **参考价值**：理解目标驱动代理和个性设计\r\n+\r\n+### 3.6 用支持向量机为短期记忆建模 ⭐⭐⭐\r\n+\r\n+- **项目已有**：可能有基础AI系统\r\n+- **掌握程度**：部分掌握，有AI开发经验，但可以学习支持向量机（SVM）应用\r\n+- **学习价值**：学习用支持向量机为短期记忆建模，实现AI记忆系统\r\n+- **学习内容**：\r\n+  - 支持向量机简介\r\n+  - 短期记忆模型化\r\n+  - CPU的消耗限制\r\n+- **应用场景**：\r\n+  - AI记忆系统\r\n+  - 短期记忆建模\r\n+  - 机器学习应用\r\n+- **Unity工具**：需要自己实现\r\n+- **参考价值**：理解支持向量机在游戏AI中的应用\r\n+\r\n+### 3.7 使用战力值评估模型进行战争役分析 ⭐⭐⭐\r\n+\r\n+- **项目已有**：可能有基础战斗系统\r\n+- **掌握程度**：部分掌握，有战斗系统使用经验，但可以学习战力值评估模型\r\n+- **学习价值**：学习使用战力值评估模型进行战争役分析，实现战斗评估系统\r\n+- **学习内容**：\r\n+  - 基本公式\r\n+  - 计算兵力\r\n+  - 计算潜在兵力\r\n+  - 为武器效力进行建模\r\n+  - 获得一个理论上的战争结局\r\n+  - 关于CEV\r\n+  - 一个QJM系统的例子\r\n+  - 局限性\r\n+- **应用场景**：\r\n+  - 战斗评估系统\r\n+  - 战争役分析\r\n+  - 战力值评估\r\n+- **Unity工具**：需要自己实现\r\n+- **参考价值**：理解战力值评估模型在游戏中的应用\r\n+\r\n ## 总结\r\n \r\n **待学习的AI技术**：\r\n 1. ⭐⭐⭐ **Steering Behaviors**：定向行为系统，AI移动行为基础\r\n"
                },
                {
                    "date": 1765968863085,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -483,8 +483,14 @@\n 16. ⭐⭐⭐ **人工势场**：快速目标评级系统\r\n 17. ⭐⭐⭐ **Lanchester损耗模型**：战斗结果预测系统\r\n 18. ⭐⭐⭐ **智能规划系统**：长期目标规划系统\r\n 19. ⭐⭐⭐ **动态A*(D*)算法**：最小重新规划开销的寻路算法\r\n+20. ⭐⭐⭐ **NPC合作行为**：独立非玩家角色合作行为的实现\r\n+21. ⭐⭐⭐ **基于行为的架构**：针对游戏的基于行为的机器人架构\r\n+22. ⭐⭐⭐ **模糊感知器+行为网络**：目标驱动的机器人构建\r\n+23. ⭐⭐⭐ **目标驱动代理**：具有个性的目标驱动代理\r\n+24. ⭐⭐⭐ **支持向量机**：用支持向量机为短期记忆建模\r\n+25. ⭐⭐⭐ **战力值评估模型**：使用战力值评估模型进行战争役分析\r\n \r\n **学习建议**：\r\n - 按需学习，根据项目需求决定是否实现\r\n - 可以基于现有系统（网格系统、寻路系统）实现\r\n"
                },
                {
                    "date": 1765968932204,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -461,8 +461,65 @@\n   - 战力值评估\r\n - **Unity工具**：需要自己实现\r\n - **参考价值**：理解战力值评估模型在游戏中的应用\r\n \r\n+## 游戏编程精粹7\r\n+\r\n+### 3.1 用行为克隆创建有趣的代理 ⭐⭐⭐\r\n+\r\n+- **项目已有**：可能有基础AI系统\r\n+- **掌握程度**：部分掌握，有AI开发经验，但可以学习行为克隆技术\r\n+- **学习价值**：学习用行为克隆创建有趣的代理，实现机器学习驱动的AI\r\n+- **学习内容**：\r\n+  - 实例:The Demo Game\r\n+  - 行为克隆技术\r\n+  - 机器学习应用\r\n+- **应用场景**：\r\n+  - 机器学习驱动的AI\r\n+  - 行为克隆系统\r\n+  - 有趣的代理创建\r\n+- **Unity工具**：\r\n+  - Unity ML-Agents（机器学习，可能支持行为克隆）\r\n+  - ⚠️ **需要自己实现**：行为克隆系统\r\n+- **参考价值**：理解行为克隆在游戏AI中的应用\r\n+\r\n+### 3.4 有关态度的一切:为意见、声望和NPC个性构建单元 ⭐⭐⭐\r\n+\r\n+- **项目已有**：可能有基础NPC系统\r\n+- **掌握程度**：部分掌握，有NPC开发经验，但可以学习NPC个性系统\r\n+- **学习价值**：学习为意见、声望和NPC个性构建单元，实现复杂的NPC个性系统\r\n+- **学习内容**：\r\n+  - 简介\r\n+  - 态度\r\n+  - 态度里有什么\r\n+  - 复杂的态度对象\r\n+  - 态度和行为\r\n+  - 说服和影响\r\n+  - 态度的社会交换\r\n+  - 另一个例子\r\n+  - 注意事项和结论\r\n+- **应用场景**：\r\n+  - NPC个性系统\r\n+  - 意见和声望系统\r\n+  - 复杂的态度建模\r\n+- **Unity工具**：需要自己实现\r\n+- **参考价值**：理解NPC个性系统在游戏中的应用\r\n+\r\n+### 3.6 面向目标的计划合并 ⭐⭐⭐\r\n+\r\n+- **项目已有**：可能有基础规划系统\r\n+- **掌握程度**：部分掌握，有规划系统使用经验，但可以学习目标计划合并\r\n+- **学习价值**：学习面向目标的计划合并，实现多目标协调规划\r\n+- **学习内容**：\r\n+  - 回顾面向目标的计划系统\r\n+  - 用于面向目标计划的计划合并\r\n+- **应用场景**：\r\n+  - 多目标协调规划\r\n+  - 计划合并系统\r\n+  - 目标驱动规划\r\n+- **Unity工具**：需要自己实现\r\n+- **参考价值**：理解目标计划合并在游戏AI中的应用\r\n+\r\n ## 总结\r\n \r\n **待学习的AI技术**：\r\n 1. ⭐⭐⭐ **Steering Behaviors**：定向行为系统，AI移动行为基础\r\n"
                },
                {
                    "date": 1765968997092,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -546,8 +546,11 @@\n 22. ⭐⭐⭐ **模糊感知器+行为网络**：目标驱动的机器人构建\r\n 23. ⭐⭐⭐ **目标驱动代理**：具有个性的目标驱动代理\r\n 24. ⭐⭐⭐ **支持向量机**：用支持向量机为短期记忆建模\r\n 25. ⭐⭐⭐ **战力值评估模型**：使用战力值评估模型进行战争役分析\r\n+26. ⭐⭐⭐ **行为克隆**：用行为克隆创建有趣的代理\r\n+27. ⭐⭐⭐ **NPC个性系统**：为意见、声望和NPC个性构建单元\r\n+28. ⭐⭐⭐ **目标计划合并**：面向目标的计划合并\r\n \r\n **学习建议**：\r\n - 按需学习，根据项目需求决定是否实现\r\n - 可以基于现有系统（网格系统、寻路系统）实现\r\n"
                },
                {
                    "date": 1765971303755,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -507,9 +507,9 @@\n ### 3.6 面向目标的计划合并 ⭐⭐⭐\r\n \r\n - **项目已有**：可能有基础规划系统\r\n - **掌握程度**：部分掌握，有规划系统使用经验，但可以学习目标计划合并\r\n-- **学习价值**：学习面向目标的计划合并，实现多目标协调规划\r\n+- **学习价值**：学习面向目标的计划合并，实现多目标协调规划        ，                                  \r\n - **学习内容**：\r\n   - 回顾面向目标的计划系统\r\n   - 用于面向目标计划的计划合并\r\n - **应用场景**：\r\n"
                },
                {
                    "date": 1765979760649,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -1,558 +1,558 @@\n-# 待学习AI技术（⭐⭐⭐）\r\n-\r\n-> 本文档整合了《游戏编程精粹》第1-7卷中项目部分掌握需要补充完善的AI技术。\r\n-\r\n-## 游戏编程精粹1\r\n-\r\n-### 5. Steering Behaviors（定向行为系统） ⭐⭐⭐\r\n-\r\n-- **项目已有**：可能有基础移动系统\r\n-- **掌握程度**：部分掌握，有移动系统使用经验，但可以学习Steering Behaviors系统\r\n-- **学习价值**：学习Reynolds提出的基础行为系统，实现各种移动行为\r\n-- **学习内容**：\r\n-  - Seek（寻找目标）\r\n-  - Flee（逃离目标）\r\n-  - Arrive（到达目标，带减速）\r\n-  - Pursue（追逐移动目标）\r\n-  - Evade（躲避移动目标）\r\n-  - Align（对齐朝向）\r\n-  - VelocityMatch（速度匹配）\r\n-  - Wander（漫游）\r\n-  - AvoidWall/AvoidAgent（避障）\r\n-- **应用场景**：\r\n-  - AI移动行为\r\n-  - 群体行为基础\r\n-  - 动态避障系统\r\n-- **Unity工具**：需要自己实现\r\n-- **参考代码**：`ReadNote/游戏编程精粹/1/代码/SteeringBehaviors(定向行为系统).md`\r\n-\r\n-### 5. Flocking（群集行为） ⭐⭐⭐\r\n-\r\n-- **项目已有**：可能有基础移动系统\r\n-- **掌握程度**：部分掌握，有移动系统使用经验，但可以学习Flocking群集行为\r\n-- **学习价值**：学习Craig Reynolds提出的分布式行为模型，模拟鸟群、鱼群等生物群体行为\r\n-- **学习内容**：\r\n-  - 四个基本规则（Reynolds规则）：\r\n-    1. 分离（Separation）：避免与邻近个体过于接近\r\n-    2. 对齐（Alignment）：与邻近个体的平均航向和速度对齐\r\n-    3. 聚集（Cohesion）：向邻近个体的平均位置移动\r\n-    4. 躲避（Avoidance）：避免撞上局部区域内的障碍或敌人\r\n-  - 无状态特性\r\n-  - 矢量累积机制\r\n-  - 性能优化（空间分区、邻居限制）\r\n-- **应用场景**：\r\n-  - 群体AI行为\r\n-  - 鸟群、鱼群模拟\r\n-  - RTS/RPG中的群体动画\r\n-- **Unity工具**：需要自己实现\r\n-- **参考代码**：`ReadNote/游戏编程精粹/1/代码/Flocking群集行为.md`\r\n-\r\n-### 5. 模糊逻辑（Fuzzy Logic） ⭐⭐⭐\r\n-\r\n-- **项目已有**：可能有基础决策系统\r\n-- **掌握程度**：部分掌握，有决策系统使用经验，但可以学习模糊逻辑决策系统\r\n-- **学习价值**：学习处理不确定性和模糊性的数学方法，实现平滑的AI决策\r\n-- **学习内容**：\r\n-  - 模糊集合和隶属度函数\r\n-  - 模糊推理（Fuzzy Inference）：\r\n-    1. 模糊化（Fuzzification）\r\n-    2. 规则评估（Rule Evaluation）\r\n-    3. 聚合（Aggregation）\r\n-    4. 去模糊化（Defuzzification）\r\n-  - 典型隶属度函数（三角形、梯形、S形）\r\n-  - 模糊逻辑运算（AND、OR、NOT）\r\n-- **应用场景**：\r\n-  - AI决策系统\r\n-  - NPC行为选择\r\n-  - 难度调整\r\n-  - 资源管理\r\n-- **Unity工具**：需要自己实现\r\n-- **参考代码**：`ReadNote/游戏编程精粹/1/代码/模糊逻辑(FuzzyLogic).md`\r\n-\r\n-### 5. 神经网络（Neural Networks） ⭐⭐⭐\r\n-\r\n-- **项目已有**：可能有基础AI系统\r\n-- **掌握程度**：部分掌握，有AI开发经验，但可以学习神经网络系统\r\n-- **学习价值**：学习模拟生物神经系统的计算模型，实现复杂的非线性映射\r\n-- **学习内容**：\r\n-  - 神经单元（Neuron）结构\r\n-  - 激活函数（Sigmoid、ReLU、Tanh）\r\n-  - 多层神经网络\r\n-  - Hebbian学习规则\r\n-  - 前向传播和反向传播\r\n-- **应用场景**：\r\n-  - AI决策\r\n-  - 行为预测\r\n-  - 难度调整\r\n-  - NPC行为学习\r\n-- **Unity工具**：Unity ML-Agents（机器学习）、需要自己实现基础神经网络\r\n-- **参考代码**：`ReadNote/游戏编程精粹/1/代码/神经网络(Neural Networks).md`\r\n-\r\n-### 5. 影响力地图（Influence Map） ⭐⭐⭐\r\n-\r\n-- **项目已有**：可能有基础网格系统（GridSystem）\r\n-- **掌握程度**：部分掌握，有网格系统使用经验，但可以学习影响力地图系统\r\n-- **学习价值**：学习用于AI决策的地图系统，表示地图上各区域的重要性\r\n-- **学习内容**：\r\n-  - 影响力传播算法\r\n-  - 合意值计算（Desirability）\r\n-  - 地形考虑\r\n-  - 3D环境应用\r\n-  - 影响力衰减（线性衰减或指数衰减）\r\n-- **应用场景**：\r\n-  - RTS游戏中的战略决策\r\n-  - 单位部署\r\n-  - 资源点选择\r\n-  - 战术位置评估\r\n-- **Unity工具**：需要自己实现，可以基于现有的网格系统和范围查找策略实现\r\n-- **参考代码**：`ReadNote/游戏编程精粹/1/代码/影响力地图(InfluenceMap).md`\r\n-\r\n-### 5. 策略评估技术 ⭐⭐⭐\r\n-\r\n-- **项目已有**：可能有基础决策系统\r\n-- **掌握程度**：部分掌握，有决策系统使用经验，但可以学习策略评估技术\r\n-- **学习价值**：学习资源分配树、依存图等策略评估技术\r\n-- **学习内容**：\r\n-  - 资源分配树\r\n-  - 依存图\r\n-  - 策略决策\r\n-  - 经济规划\r\n-- **应用场景**：\r\n-  - RTS游戏的经济规划\r\n-  - 资源分配\r\n-  - 策略类游戏\r\n-- **Unity工具**：需要自己实现\r\n-- **参考代码**：`ReadNote/游戏编程精粹/1/代码/策略评估技术(StrategyEvaluation).md`\r\n-\r\n-### 5. 地形推理 ⭐⭐⭐\r\n-\r\n-- **项目已有**：可能有基础地形系统（EBattleTerrain地形类型枚举）\r\n-- **掌握程度**：部分掌握，有地形使用经验，但可以学习地形推理技术\r\n-- **学习价值**：学习中继点（Waypoint）、战术分析等地形推理技术\r\n-- **学习内容**：\r\n-  - 中继点系统\r\n-  - 战术分析\r\n-  - 地形表示\r\n-  - 从经验中学习\r\n-- **应用场景**：\r\n-  - 战术位置评估\r\n-  - 防御点识别\r\n-  - 进攻路线规划\r\n-- **Unity工具**：Unity NavMesh（基础支持）、需要自己实现高级功能\r\n-- **参考代码**：`ReadNote/游戏编程精粹/1/代码/地形推理(TerrainReasoning).md`\r\n-\r\n-### 5. 可视点寻径（Points-of-Visibility Pathfinding） ⭐⭐⭐\r\n-\r\n-- **项目已有**：A*寻路算法实现\r\n-- **掌握程度**：部分掌握，有A*寻路经验，但可以学习可视点寻径优化技术\r\n-- **学习价值**：学习可视点寻径优化技术，用于优化路径查找\r\n-- **学习内容**：\r\n-  - 可视点寻径算法\r\n-  - 存储到每个点的最短路径\r\n-  - 轮廓区\r\n-  - 空间分区系统\r\n-- **应用场景**：\r\n-  - 路径优化\r\n-  - 大规模寻径系统\r\n-  - 作为A*算法的优化技术\r\n-- **Unity工具**：Unity NavMesh（基础支持）、需要自己实现高级优化\r\n-- **参考代码**：`ReadNote/游戏编程精粹/1/代码/可视点寻径(PointsOfVisibility).md`\r\n-\r\n-## 游戏编程精粹3\r\n-\r\n-### 3.9 区域游览（寻径模式扩展） ⭐⭐⭐\r\n-\r\n-- **项目已有**：A*寻路算法实现和Unity NavMesh系统\r\n-- **掌握程度**：部分掌握，有基础寻径经验，但可以学习区域游览模式\r\n-- **学习价值**：学习寻径模式扩展，实现区域游览功能\r\n-- **学习内容**：\r\n-  - 区域游览的概念\r\n-  - 寻径模式扩展\r\n-  - 区域识别和遍历\r\n-- **应用场景**：\r\n-  - 巡逻系统\r\n-  - 区域探索\r\n-  - 寻径模式扩展\r\n-- **Unity工具**：Unity NavMesh（基础支持）、需要自己实现区域游览\r\n-\r\n-### 3.8 在寻径与碰撞之间选择一种关系（高级方法） ⭐⭐⭐\r\n-\r\n-- **项目已有**：Unity NavMesh系统和物理碰撞系统\r\n-- **掌握程度**：部分掌握，有基础寻径与碰撞经验，但可以学习三种关系处理方法\r\n-- **学习价值**：学习寻径与碰撞的三种关系处理方法，实现更精确的移动控制\r\n-- **学习内容**：\r\n-  - 方法1：具有容错性的AI（容错寻径）\r\n-  - 方法2：在无障碍空间一个子集内的寻径（受限寻径）\r\n-  - 方法3：使用寻径器本身处理人物碰撞（寻径器碰撞处理）\r\n-- **应用场景**：\r\n-  - 需要精确碰撞控制的游戏\r\n-  - 多单位密集移动场景\r\n-  - 需要容错性的AI系统\r\n-- **Unity工具**：Unity NavMesh + Physics（基础支持）、需要自己实现高级方法\r\n-\r\n-## 游戏编程精粹4\r\n-\r\n-### 4.3 非玩家角色决策:处理随机问题 ⭐⭐⭐\r\n-\r\n-- **项目已有**：可能有基础决策系统\r\n-- **掌握程度**：部分掌握，有决策系统使用经验，但可以学习处理随机问题的决策系统\r\n-- **学习价值**：学习使用动态规划算法处理NPC决策中的随机问题\r\n-- **学习内容**：\r\n-  - 动态规划算法\r\n-  - 处理随机问题的决策方法\r\n-  - 代码实现\r\n-  - 优化技巧\r\n-  - DP算法的其他应用\r\n-- **应用场景**：\r\n-  - NPC决策系统\r\n-  - 随机环境下的决策\r\n-  - 动态规划在游戏AI中的应用\r\n-- **Unity工具**：需要自己实现\r\n-- **参考价值**：理解动态规划在AI决策中的应用\r\n-\r\n-### 4.4 一个基于效用的面向对象决策架构 ⭐⭐⭐\r\n-\r\n-- **项目已有**：可能有基础决策系统\r\n-- **掌握程度**：部分掌握，有决策系统使用经验，但可以学习基于效用的决策架构\r\n-- **学习价值**：学习基于效用的面向对象决策架构，实现更灵活的决策系统\r\n-- **学习内容**：\r\n-  - 决策树\r\n-  - 基于对象的更好的体系结构\r\n-  - 期望值计算\r\n-  - 其他的决策准则\r\n-- **应用场景**：\r\n-  - NPC决策系统\r\n-  - 基于效用的决策\r\n-  - 面向对象的AI架构\r\n-- **Unity工具**：需要自己实现\r\n-- **参考价值**：理解效用决策架构的设计思想\r\n-\r\n-### 4.5 一个分布式推理投票架构 ⭐⭐⭐\r\n-\r\n-- **项目已有**：可能有基础推理系统\r\n-- **掌握程度**：部分掌握，有推理系统使用经验，但可以学习分布式推理投票架构\r\n-- **学习价值**：学习分布式推理投票架构，实现多系统协作的决策\r\n-- **学习内容**：\r\n-  - 分布式推理\r\n-  - 操纵仲裁者(Steering Arbiter)范例\r\n-  - 选择投票空间\r\n-- **应用场景**：\r\n-  - 多系统协作决策\r\n-  - 分布式AI系统\r\n-  - 投票机制在AI中的应用\r\n-- **Unity工具**：需要自己实现\r\n-- **参考价值**：理解分布式推理和投票机制\r\n-\r\n-### 4.6 吸引子和排斥子 ⭐⭐⭐\r\n-\r\n-- **项目已有**：可能有基础移动系统\r\n-- **掌握程度**：部分掌握，有移动系统使用经验，但可以学习吸引子和排斥子系统\r\n-- **学习价值**：学习吸引子和排斥子系统，实现更自然的AI移动行为\r\n-- **学习内容**：\r\n-  - 合力计算\r\n-  - 引力曲线\r\n-  - 吸引曲线的和\r\n-  - 对应于特定配对的特定曲线\r\n-  - 动态曲线\r\n-  - 点、线、面\r\n-  - AI控制的层次\r\n-  - 动画系统的交互\r\n-  - 移动(Steering)\r\n-- **应用场景**：\r\n-  - AI移动行为\r\n-  - 与Steering Behaviors相关\r\n-  - 自然移动系统\r\n-- **Unity工具**：需要自己实现\r\n-- **参考价值**：理解吸引子和排斥子在AI移动中的应用\r\n-\r\n-### 4.7 高级RTS游戏造墙算法 ⭐⭐⭐\r\n-\r\n-- **项目已有**：可能有基础RTS系统\r\n-- **掌握程度**：部分掌握，有RTS开发经验，但可以学习高级造墙算法\r\n-- **学习价值**：学习高级RTS游戏造墙算法，实现智能建筑系统\r\n-- **学习内容**：\r\n-  - 算法实现\r\n-  - 算法改进\r\n-  - 输出链表的形式\r\n-- **应用场景**：\r\n-  - RTS游戏\r\n-  - 智能建筑系统\r\n-  - 自动造墙\r\n-- **Unity工具**：需要自己实现\r\n-- **参考价值**：理解RTS特定算法的实现思路\r\n-\r\n-## 游戏编程精粹5\r\n-\r\n-### 3.2 使用人工势场实现快速目标评级 ⭐⭐⭐\r\n-\r\n-- **项目已有**：可能有基础AI系统\r\n-- **掌握程度**：部分掌握，有AI开发经验，但可以学习人工势场系统\r\n-- **学习价值**：学习使用人工势场实现快速目标评级，实现智能目标选择\r\n-- **学习内容**：\r\n-  - 基本思想\r\n-  - 公式\r\n-  - 势值函数的评估\r\n-  - 可视化\r\n-  - 方向场的应用\r\n-  - 多维扩展\r\n-- **应用场景**：\r\n-  - 目标选择系统\r\n-  - 快速目标评级\r\n-  - 智能决策系统\r\n-- **Unity工具**：需要自己实现\r\n-- **参考价值**：理解人工势场在AI决策中的应用\r\n-\r\n-### 3.3 利用Lanchester损耗模型来预测战斗结果 ⭐⭐⭐\r\n-\r\n-- **项目已有**：可能有基础战斗系统\r\n-- **掌握程度**：部分掌握，有战斗系统使用经验，但可以学习战斗预测模型\r\n-- **学习价值**：学习利用Lanchester损耗模型来预测战斗结果，实现智能战斗评估\r\n-- **学习内容**：\r\n-  - 概述\r\n-  - 场景1:全体混战\r\n-  - 场景2:狭窄的石阶\r\n-  - 场景3:炮战\r\n-  - 场景4:关底Boss\r\n-  - 关于战斗力的再讨论\r\n-  - 局限性\r\n-- **应用场景**：\r\n-  - 战斗预测系统\r\n-  - 战斗结果评估\r\n-  - 战术决策系统\r\n-- **Unity工具**：需要自己实现\r\n-- **参考价值**：理解战斗预测模型在AI决策中的应用\r\n-\r\n-### 3.4 为游戏AI实现一个实用的智能规划系统 ⭐⭐⭐\r\n-\r\n-- **项目已有**：可能有基础决策系统\r\n-- **掌握程度**：部分掌握，有决策系统使用经验，但可以学习智能规划系统\r\n-- **学习价值**：学习为游戏AI实现一个实用的智能规划系统，实现长期目标规划\r\n-- **学习内容**：\r\n-  - 规划系统的框架\r\n-  - 规划域\r\n-  - 一个多主体规划器的例子\r\n-  - 规划的搜索\r\n-  - 几个应用问题\r\n-  - 优化\r\n-- **应用场景**：\r\n-  - 长期目标规划\r\n-  - 多主体协作\r\n-  - 智能规划系统\r\n-- **Unity工具**：需要自己实现\r\n-- **参考价值**：理解智能规划系统在游戏AI中的应用\r\n-\r\n-### 3.8 实现最小重新规划开销的先进寻路算法:动态A*(D*)算法 ⭐⭐⭐\r\n-\r\n-- **项目已有**：A*寻路算法实现\r\n-- **掌握程度**：部分掌握，有A*寻路经验，但可以学习动态A*算法\r\n-- **学习价值**：学习动态A*(D*)算法，实现最小重新规划开销的寻路系统\r\n-- **学习内容**：\r\n-  - D*算法\r\n-  - D*算法的实现细节\r\n-  - 实例\r\n-  - 在游戏中又如何呢?\r\n-- **应用场景**：\r\n-  - 动态环境寻路\r\n-  - 需要频繁重新规划的寻路\r\n-  - 最小开销重新规划\r\n-- **Unity工具**：Unity NavMesh（基础支持）、需要自己实现D*算法\r\n-- **参考价值**：理解动态寻路算法在游戏中的应用\r\n-\r\n-## 游戏编程精粹6\r\n-\r\n-### 3.2 独立非玩家角色合作行为的实现 ⭐⭐⭐\r\n-\r\n-- **项目已有**：可能有基础NPC系统\r\n-- **掌握程度**：部分掌握，有NPC开发经验，但可以学习NPC合作行为系统\r\n-- **学习价值**：学习独立非玩家角色合作行为的实现，实现NPC协作系统\r\n-- **学习内容**：\r\n-  - 可能的解决方案\r\n-  - 非玩家角色的结构\r\n-  - 合作的机制\r\n-  - 例子:合作寻找玩家\r\n-- **应用场景**：\r\n-  - NPC协作系统\r\n-  - 团队AI行为\r\n-  - 多NPC协调\r\n-- **Unity工具**：需要自己实现\r\n-- **参考价值**：理解NPC合作行为的实现思路\r\n-\r\n-### 3.3 针对游戏的基于行为的机器人架构 ⭐⭐⭐\r\n-\r\n-- **项目已有**：可能有基础AI系统\r\n-- **掌握程度**：部分掌握，有AI开发经验，但可以学习基于行为的架构\r\n-- **学习价值**：学习针对游戏的基于行为的机器人架构，实现行为驱动AI\r\n-- **学习内容**：\r\n-  - 包容体结构\r\n-  - 扩展的行为网络\r\n-  - 讨论\r\n-- **应用场景**：\r\n-  - 行为驱动AI\r\n-  - 基于行为的机器人\r\n-  - 行为网络系统\r\n-- **Unity工具**：需要自己实现\r\n-- **参考价值**：理解基于行为的AI架构设计\r\n-\r\n-### 3.4 使用模糊感知器、有限状态自动机和扩展的行为网络构建目标驱动的机器人 ⭐⭐⭐\r\n-\r\n-- **项目已有**：有限状态机（项目已有完整FSM系统）\r\n-- **掌握程度**：部分掌握，有FSM使用经验，但可以学习模糊感知器+行为网络组合\r\n-- **学习价值**：学习使用模糊感知器、FSM和扩展的行为网络构建目标驱动的机器人\r\n-- **学习内容**：\r\n-  - 扩展的行为网络设计\r\n-  - 层次模糊感知器\r\n-  - 有限状态自动机行为模块\r\n-- **应用场景**：\r\n-  - 目标驱动AI\r\n-  - 模糊感知器应用\r\n-  - 行为网络系统\r\n-- **Unity工具**：需要自己实现，可以基于现有FSM系统扩展\r\n-- **参考价值**：理解模糊感知器、FSM和行为网络的组合应用\r\n-\r\n-### 3.5 一个目标驱动的虚幻竞技场游戏角色程序 ⭐⭐⭐\r\n-\r\n-- **项目已有**：可能有基础AI系统\r\n-- **掌握程度**：部分掌握，有AI开发经验，但可以学习目标驱动的代理系统\r\n-- **学习价值**：学习使用扩展的行为网络制作目标驱动的具有个性的代理\r\n-- **学习内容**：\r\n-  - 扩展的行为网络\r\n-  - 行为选择的质量\r\n-  - 个性设计\r\n-- **应用场景**：\r\n-  - 目标驱动AI\r\n-  - 具有个性的代理\r\n-  - 行为网络系统\r\n-- **Unity工具**：需要自己实现\r\n-- **参考价值**：理解目标驱动代理和个性设计\r\n-\r\n-### 3.6 用支持向量机为短期记忆建模 ⭐⭐⭐\r\n-\r\n-- **项目已有**：可能有基础AI系统\r\n-- **掌握程度**：部分掌握，有AI开发经验，但可以学习支持向量机（SVM）应用\r\n-- **学习价值**：学习用支持向量机为短期记忆建模，实现AI记忆系统\r\n-- **学习内容**：\r\n-  - 支持向量机简介\r\n-  - 短期记忆模型化\r\n-  - CPU的消耗限制\r\n-- **应用场景**：\r\n-  - AI记忆系统\r\n-  - 短期记忆建模\r\n-  - 机器学习应用\r\n-- **Unity工具**：需要自己实现\r\n-- **参考价值**：理解支持向量机在游戏AI中的应用\r\n-\r\n-### 3.7 使用战力值评估模型进行战争役分析 ⭐⭐⭐\r\n-\r\n-- **项目已有**：可能有基础战斗系统\r\n-- **掌握程度**：部分掌握，有战斗系统使用经验，但可以学习战力值评估模型\r\n-- **学习价值**：学习使用战力值评估模型进行战争役分析，实现战斗评估系统\r\n-- **学习内容**：\r\n-  - 基本公式\r\n-  - 计算兵力\r\n-  - 计算潜在兵力\r\n-  - 为武器效力进行建模\r\n-  - 获得一个理论上的战争结局\r\n-  - 关于CEV\r\n-  - 一个QJM系统的例子\r\n-  - 局限性\r\n-- **应用场景**：\r\n-  - 战斗评估系统\r\n-  - 战争役分析\r\n-  - 战力值评估\r\n-- **Unity工具**：需要自己实现\r\n-- **参考价值**：理解战力值评估模型在游戏中的应用\r\n-\r\n-## 游戏编程精粹7\r\n-\r\n-### 3.1 用行为克隆创建有趣的代理 ⭐⭐⭐\r\n-\r\n-- **项目已有**：可能有基础AI系统\r\n-- **掌握程度**：部分掌握，有AI开发经验，但可以学习行为克隆技术\r\n-- **学习价值**：学习用行为克隆创建有趣的代理，实现机器学习驱动的AI\r\n-- **学习内容**：\r\n-  - 实例:The Demo Game\r\n-  - 行为克隆技术\r\n-  - 机器学习应用\r\n-- **应用场景**：\r\n-  - 机器学习驱动的AI\r\n-  - 行为克隆系统\r\n-  - 有趣的代理创建\r\n-- **Unity工具**：\r\n-  - Unity ML-Agents（机器学习，可能支持行为克隆）\r\n-  - ⚠️ **需要自己实现**：行为克隆系统\r\n-- **参考价值**：理解行为克隆在游戏AI中的应用\r\n-\r\n-### 3.4 有关态度的一切:为意见、声望和NPC个性构建单元 ⭐⭐⭐\r\n-\r\n-- **项目已有**：可能有基础NPC系统\r\n-- **掌握程度**：部分掌握，有NPC开发经验，但可以学习NPC个性系统\r\n-- **学习价值**：学习为意见、声望和NPC个性构建单元，实现复杂的NPC个性系统\r\n-- **学习内容**：\r\n-  - 简介\r\n-  - 态度\r\n-  - 态度里有什么\r\n-  - 复杂的态度对象\r\n-  - 态度和行为\r\n-  - 说服和影响\r\n-  - 态度的社会交换\r\n-  - 另一个例子\r\n-  - 注意事项和结论\r\n-- **应用场景**：\r\n-  - NPC个性系统\r\n-  - 意见和声望系统\r\n-  - 复杂的态度建模\r\n-- **Unity工具**：需要自己实现\r\n-- **参考价值**：理解NPC个性系统在游戏中的应用\r\n-\r\n-### 3.6 面向目标的计划合并 ⭐⭐⭐\r\n-\r\n-- **项目已有**：可能有基础规划系统\r\n-- **掌握程度**：部分掌握，有规划系统使用经验，但可以学习目标计划合并\r\n-- **学习价值**：学习面向目标的计划合并，实现多目标协调规划        ，                                  \r\n-- **学习内容**：\r\n-  - 回顾面向目标的计划系统\r\n-  - 用于面向目标计划的计划合并\r\n-- **应用场景**：\r\n-  - 多目标协调规划\r\n-  - 计划合并系统\r\n-  - 目标驱动规划\r\n-- **Unity工具**：需要自己实现\r\n-- **参考价值**：理解目标计划合并在游戏AI中的应用\r\n-\r\n-## 总结\r\n-\r\n-**待学习的AI技术**：\r\n-1. ⭐⭐⭐ **Steering Behaviors**：定向行为系统，AI移动行为基础\r\n-2. ⭐⭐⭐ **Flocking**：群集行为，群体AI行为\r\n-3. ⭐⭐⭐ **模糊逻辑**：模糊决策系统\r\n-4. ⭐⭐⭐ **神经网络**：AI学习系统\r\n-5. ⭐⭐⭐ **影响力地图**：战略决策系统\r\n-6. ⭐⭐⭐ **策略评估技术**：资源分配和决策\r\n-7. ⭐⭐⭐ **地形推理**：战术分析系统\r\n-8. ⭐⭐⭐ **可视点寻径**：路径优化技术\r\n-9. ⭐⭐⭐ **区域游览**：寻径模式扩展\r\n-10. ⭐⭐⭐ **寻径与碰撞**：高级关系处理方法\r\n-11. ⭐⭐⭐ **NPC决策处理随机问题**：动态规划算法\r\n-12. ⭐⭐⭐ **基于效用的决策架构**：面向对象决策系统\r\n-13. ⭐⭐⭐ **分布式推理投票架构**：多系统协作决策\r\n-14. ⭐⭐⭐ **吸引子和排斥子**：自然移动系统\r\n-15. ⭐⭐⭐ **RTS造墙算法**：智能建筑系统\r\n-16. ⭐⭐⭐ **人工势场**：快速目标评级系统\r\n-17. ⭐⭐⭐ **Lanchester损耗模型**：战斗结果预测系统\r\n-18. ⭐⭐⭐ **智能规划系统**：长期目标规划系统\r\n-19. ⭐⭐⭐ **动态A*(D*)算法**：最小重新规划开销的寻路算法\r\n-20. ⭐⭐⭐ **NPC合作行为**：独立非玩家角色合作行为的实现\r\n-21. ⭐⭐⭐ **基于行为的架构**：针对游戏的基于行为的机器人架构\r\n-22. ⭐⭐⭐ **模糊感知器+行为网络**：目标驱动的机器人构建\r\n-23. ⭐⭐⭐ **目标驱动代理**：具有个性的目标驱动代理\r\n-24. ⭐⭐⭐ **支持向量机**：用支持向量机为短期记忆建模\r\n-25. ⭐⭐⭐ **战力值评估模型**：使用战力值评估模型进行战争役分析\r\n-26. ⭐⭐⭐ **行为克隆**：用行为克隆创建有趣的代理\r\n-27. ⭐⭐⭐ **NPC个性系统**：为意见、声望和NPC个性构建单元\r\n-28. ⭐⭐⭐ **目标计划合并**：面向目标的计划合并\r\n-\r\n-**学习建议**：\r\n-- 按需学习，根据项目需求决定是否实现\r\n-- 可以基于现有系统（网格系统、寻路系统）实现\r\n-- 参考代码示例，理解原理后实现\r\n-\r\n+# 待学习AI技术（⭐⭐⭐）\n+\n+> 本文档整合了《游戏编程精粹》第1-7卷中项目部分掌握需要补充完善的AI技术。\n+\n+## 游戏编程精粹1\n+\n+### 5. Steering Behaviors（定向行为系统） ⭐⭐⭐\n+\n+- **项目已有**：可能有基础移动系统\n+- **掌握程度**：部分掌握，有移动系统使用经验，但可以学习Steering Behaviors系统\n+- **学习价值**：学习Reynolds提出的基础行为系统，实现各种移动行为\n+- **学习内容**：\n+  - Seek（寻找目标）\n+  - Flee（逃离目标）\n+  - Arrive（到达目标，带减速）\n+  - Pursue（追逐移动目标）\n+  - Evade（躲避移动目标）\n+  - Align（对齐朝向）\n+  - VelocityMatch（速度匹配）\n+  - Wander（漫游）\n+  - AvoidWall/AvoidAgent（避障）\n+- **应用场景**：\n+  - AI移动行为\n+  - 群体行为基础\n+  - 动态避障系统\n+- **Unity工具**：需要自己实现\n+- **参考代码**：`ReadNote/游戏编程精粹/1/代码/SteeringBehaviors(定向行为系统).md`\n+\n+### 5. Flocking（群集行为） ⭐⭐⭐\n+\n+- **项目已有**：可能有基础移动系统\n+- **掌握程度**：部分掌握，有移动系统使用经验，但可以学习Flocking群集行为\n+- **学习价值**：学习Craig Reynolds提出的分布式行为模型，模拟鸟群、鱼群等生物群体行为\n+- **学习内容**：\n+  - 四个基本规则（Reynolds规则）：\n+    1. 分离（Separation）：避免与邻近个体过于接近\n+    2. 对齐（Alignment）：与邻近个体的平均航向和速度对齐\n+    3. 聚集（Cohesion）：向邻近个体的平均位置移动\n+    4. 躲避（Avoidance）：避免撞上局部区域内的障碍或敌人\n+  - 无状态特性\n+  - 矢量累积机制\n+  - 性能优化（空间分区、邻居限制）\n+- **应用场景**：\n+  - 群体AI行为\n+  - 鸟群、鱼群模拟\n+  - RTS/RPG中的群体动画\n+- **Unity工具**：需要自己实现\n+- **参考代码**：`ReadNote/游戏编程精粹/1/代码/Flocking群集行为.md`\n+\n+### 5. 模糊逻辑（Fuzzy Logic） ⭐⭐⭐\n+\n+- **项目已有**：可能有基础决策系统\n+- **掌握程度**：部分掌握，有决策系统使用经验，但可以学习模糊逻辑决策系统\n+- **学习价值**：学习处理不确定性和模糊性的数学方法，实现平滑的AI决策\n+- **学习内容**：\n+  - 模糊集合和隶属度函数\n+  - 模糊推理（Fuzzy Inference）：\n+    1. 模糊化（Fuzzification）\n+    2. 规则评估（Rule Evaluation）\n+    3. 聚合（Aggregation）\n+    4. 去模糊化（Defuzzification）\n+  - 典型隶属度函数（三角形、梯形、S形）\n+  - 模糊逻辑运算（AND、OR、NOT）\n+- **应用场景**：\n+  - AI决策系统\n+  - NPC行为选择\n+  - 难度调整\n+  - 资源管理\n+- **Unity工具**：需要自己实现\n+- **参考代码**：`ReadNote/游戏编程精粹/1/代码/模糊逻辑(FuzzyLogic).md`\n+\n+### 5. 神经网络（Neural Networks） ⭐⭐⭐\n+\n+- **项目已有**：可能有基础AI系统\n+- **掌握程度**：部分掌握，有AI开发经验，但可以学习神经网络系统\n+- **学习价值**：学习模拟生物神经系统的计算模型，实现复杂的非线性映射\n+- **学习内容**：\n+  - 神经单元（Neuron）结构\n+  - 激活函数（Sigmoid、ReLU、Tanh）\n+  - 多层神经网络\n+  - Hebbian学习规则\n+  - 前向传播和反向传播\n+- **应用场景**：\n+  - AI决策\n+  - 行为预测\n+  - 难度调整\n+  - NPC行为学习\n+- **Unity工具**：Unity ML-Agents（机器学习）、需要自己实现基础神经网络\n+- **参考代码**：`ReadNote/游戏编程精粹/1/代码/神经网络(Neural Networks).md`\n+\n+### 5. 影响力地图（Influence Map） ⭐⭐⭐\n+\n+- **项目已有**：可能有基础网格系统（GridSystem）\n+- **掌握程度**：部分掌握，有网格系统使用经验，但可以学习影响力地图系统\n+- **学习价值**：学习用于AI决策的地图系统，表示地图上各区域的重要性\n+- **学习内容**：\n+  - 影响力传播算法\n+  - 合意值计算（Desirability）\n+  - 地形考虑\n+  - 3D环境应用\n+  - 影响力衰减（线性衰减或指数衰减）\n+- **应用场景**：\n+  - RTS游戏中的战略决策\n+  - 单位部署\n+  - 资源点选择\n+  - 战术位置评估\n+- **Unity工具**：需要自己实现，可以基于现有的网格系统和范围查找策略实现\n+- **参考代码**：`ReadNote/游戏编程精粹/1/代码/影响力地图(InfluenceMap).md`\n+\n+### 5. 策略评估技术 ⭐⭐⭐\n+\n+- **项目已有**：可能有基础决策系统\n+- **掌握程度**：部分掌握，有决策系统使用经验，但可以学习策略评估技术\n+- **学习价值**：学习资源分配树、依存图等策略评估技术\n+- **学习内容**：\n+  - 资源分配树\n+  - 依存图\n+  - 策略决策\n+  - 经济规划\n+- **应用场景**：\n+  - RTS游戏的经济规划\n+  - 资源分配\n+  - 策略类游戏\n+- **Unity工具**：需要自己实现\n+- **参考代码**：`ReadNote/游戏编程精粹/1/代码/策略评估技术(StrategyEvaluation).md`\n+\n+### 5. 地形推理 ⭐⭐⭐\n+\n+- **项目已有**：可能有基础地形系统（EBattleTerrain地形类型枚举）\n+- **掌握程度**：部分掌握，有地形使用经验，但可以学习地形推理技术\n+- **学习价值**：学习中继点（Waypoint）、战术分析等地形推理技术\n+- **学习内容**：\n+  - 中继点系统\n+  - 战术分析\n+  - 地形表示\n+  - 从经验中学习\n+- **应用场景**：\n+  - 战术位置评估\n+  - 防御点识别\n+  - 进攻路线规划\n+- **Unity工具**：Unity NavMesh（基础支持）、需要自己实现高级功能\n+- **参考代码**：`ReadNote/游戏编程精粹/1/代码/地形推理(TerrainReasoning).md`\n+\n+### 5. 可视点寻径（Points-of-Visibility Pathfinding） ⭐⭐⭐\n+\n+- **项目已有**：A*寻路算法实现\n+- **掌握程度**：部分掌握，有A*寻路经验，但可以学习可视点寻径优化技术\n+- **学习价值**：学习可视点寻径优化技术，用于优化路径查找\n+- **学习内容**：\n+  - 可视点寻径算法\n+  - 存储到每个点的最短路径\n+  - 轮廓区\n+  - 空间分区系统\n+- **应用场景**：\n+  - 路径优化\n+  - 大规模寻径系统\n+  - 作为A*算法的优化技术\n+- **Unity工具**：Unity NavMesh（基础支持）、需要自己实现高级优化\n+- **参考代码**：`ReadNote/游戏编程精粹/1/代码/可视点寻径(PointsOfVisibility).md`\n+\n+## 游戏编程精粹3\n+\n+### 3.9 区域游览（寻径模式扩展） ⭐⭐⭐\n+\n+- **项目已有**：A*寻路算法实现和Unity NavMesh系统\n+- **掌握程度**：部分掌握，有基础寻径经验，但可以学习区域游览模式\n+- **学习价值**：学习寻径模式扩展，实现区域游览功能\n+- **学习内容**：\n+  - 区域游览的概念\n+  - 寻径模式扩展\n+  - 区域识别和遍历\n+- **应用场景**：\n+  - 巡逻系统\n+  - 区域探索\n+  - 寻径模式扩展\n+- **Unity工具**：Unity NavMesh（基础支持）、需要自己实现区域游览\n+\n+### 3.8 在寻径与碰撞之间选择一种关系（高级方法） ⭐⭐⭐\n+\n+- **项目已有**：Unity NavMesh系统和物理碰撞系统\n+- **掌握程度**：部分掌握，有基础寻径与碰撞经验，但可以学习三种关系处理方法\n+- **学习价值**：学习寻径与碰撞的三种关系处理方法，实现更精确的移动控制\n+- **学习内容**：\n+  - 方法1：具有容错性的AI（容错寻径）\n+  - 方法2：在无障碍空间一个子集内的寻径（受限寻径）\n+  - 方法3：使用寻径器本身处理人物碰撞（寻径器碰撞处理）\n+- **应用场景**：\n+  - 需要精确碰撞控制的游戏\n+  - 多单位密集移动场景\n+  - 需要容错性的AI系统\n+- **Unity工具**：Unity NavMesh + Physics（基础支持）、需要自己实现高级方法\n+\n+## 游戏编程精粹4\n+\n+### 4.3 非玩家角色决策:处理随机问题 ⭐⭐⭐\n+\n+- **项目已有**：可能有基础决策系统\n+- **掌握程度**：部分掌握，有决策系统使用经验，但可以学习处理随机问题的决策系统\n+- **学习价值**：学习使用动态规划算法处理NPC决策中的随机问题\n+- **学习内容**：\n+  - 动态规划算法\n+  - 处理随机问题的决策方法\n+  - 代码实现\n+  - 优化技巧\n+  - DP算法的其他应用\n+- **应用场景**：\n+  - NPC决策系统\n+  - 随机环境下的决策\n+  - 动态规划在游戏AI中的应用\n+- **Unity工具**：需要自己实现\n+- **参考价值**：理解动态规划在AI决策中的应用\n+\n+### 4.4 一个基于效用的面向对象决策架构 ⭐⭐⭐\n+\n+- **项目已有**：可能有基础决策系统\n+- **掌握程度**：部分掌握，有决策系统使用经验，但可以学习基于效用的决策架构\n+- **学习价值**：学习基于效用的面向对象决策架构，实现更灵活的决策系统\n+- **学习内容**：\n+  - 决策树\n+  - 基于对象的更好的体系结构\n+  - 期望值计算\n+  - 其他的决策准则\n+- **应用场景**：\n+  - NPC决策系统\n+  - 基于效用的决策\n+  - 面向对象的AI架构\n+- **Unity工具**：需要自己实现\n+- **参考价值**：理解效用决策架构的设计思想\n+\n+### 4.5 一个分布式推理投票架构 ⭐⭐⭐\n+\n+- **项目已有**：可能有基础推理系统\n+- **掌握程度**：部分掌握，有推理系统使用经验，但可以学习分布式推理投票架构\n+- **学习价值**：学习分布式推理投票架构，实现多系统协作的决策\n+- **学习内容**：\n+  - 分布式推理\n+  - 操纵仲裁者(Steering Arbiter)范例\n+  - 选择投票空间\n+- **应用场景**：\n+  - 多系统协作决策\n+  - 分布式AI系统\n+  - 投票机制在AI中的应用\n+- **Unity工具**：需要自己实现\n+- **参考价值**：理解分布式推理和投票机制\n+\n+### 4.6 吸引子和排斥子 ⭐⭐⭐\n+\n+- **项目已有**：可能有基础移动系统\n+- **掌握程度**：部分掌握，有移动系统使用经验，但可以学习吸引子和排斥子系统\n+- **学习价值**：学习吸引子和排斥子系统，实现更自然的AI移动行为\n+- **学习内容**：\n+  - 合力计算\n+  - 引力曲线\n+  - 吸引曲线的和\n+  - 对应于特定配对的特定曲线\n+  - 动态曲线\n+  - 点、线、面\n+  - AI控制的层次\n+  - 动画系统的交互\n+  - 移动(Steering)\n+- **应用场景**：\n+  - AI移动行为\n+  - 与Steering Behaviors相关\n+  - 自然移动系统\n+- **Unity工具**：需要自己实现\n+- **参考价值**：理解吸引子和排斥子在AI移动中的应用\n+\n+### 4.7 高级RTS游戏造墙算法 ⭐⭐⭐\n+\n+- **项目已有**：可能有基础RTS系统\n+- **掌握程度**：部分掌握，有RTS开发经验，但可以学习高级造墙算法\n+- **学习价值**：学习高级RTS游戏造墙算法，实现智能建筑系统\n+- **学习内容**：\n+  - 算法实现\n+  - 算法改进\n+  - 输出链表的形式\n+- **应用场景**：\n+  - RTS游戏\n+  - 智能建筑系统\n+  - 自动造墙\n+- **Unity工具**：需要自己实现\n+- **参考价值**：理解RTS特定算法的实现思路\n+\n+## 游戏编程精粹5\n+\n+### 3.2 使用人工势场实现快速目标评级 ⭐⭐⭐\n+\n+- **项目已有**：可能有基础AI系统\n+- **掌握程度**：部分掌握，有AI开发经验，但可以学习人工势场系统\n+- **学习价值**：学习使用人工势场实现快速目标评级，实现智能目标选择\n+- **学习内容**：\n+  - 基本思想\n+  - 公式\n+  - 势值函数的评估\n+  - 可视化\n+  - 方向场的应用\n+  - 多维扩展\n+- **应用场景**：\n+  - 目标选择系统\n+  - 快速目标评级\n+  - 智能决策系统\n+- **Unity工具**：需要自己实现\n+- **参考价值**：理解人工势场在AI决策中的应用\n+\n+### 3.3 利用Lanchester损耗模型来预测战斗结果 ⭐⭐⭐\n+\n+- **项目已有**：可能有基础战斗系统\n+- **掌握程度**：部分掌握，有战斗系统使用经验，但可以学习战斗预测模型\n+- **学习价值**：学习利用Lanchester损耗模型来预测战斗结果，实现智能战斗评估\n+- **学习内容**：\n+  - 概述\n+  - 场景1:全体混战\n+  - 场景2:狭窄的石阶\n+  - 场景3:炮战\n+  - 场景4:关底Boss\n+  - 关于战斗力的再讨论\n+  - 局限性\n+- **应用场景**：\n+  - 战斗预测系统\n+  - 战斗结果评估\n+  - 战术决策系统\n+- **Unity工具**：需要自己实现\n+- **参考价值**：理解战斗预测模型在AI决策中的应用\n+\n+### 3.4 为游戏AI实现一个实用的智能规划系统 ⭐⭐⭐\n+\n+- **项目已有**：可能有基础决策系统\n+- **掌握程度**：部分掌握，有决策系统使用经验，但可以学习智能规划系统\n+- **学习价值**：学习为游戏AI实现一个实用的智能规划系统，实现长期目标规划\n+- **学习内容**：\n+  - 规划系统的框架\n+  - 规划域\n+  - 一个多主体规划器的例子\n+  - 规划的搜索\n+  - 几个应用问题\n+  - 优化\n+- **应用场景**：\n+  - 长期目标规划\n+  - 多主体协作\n+  - 智能规划系统\n+- **Unity工具**：需要自己实现\n+- **参考价值**：理解智能规划系统在游戏AI中的应用\n+\n+### 3.8 实现最小重新规划开销的先进寻路算法:动态A*(D*)算法 ⭐⭐⭐\n+\n+- **项目已有**：A*寻路算法实现\n+- **掌握程度**：部分掌握，有A*寻路经验，但可以学习动态A*算法\n+- **学习价值**：学习动态A*(D*)算法，实现最小重新规划开销的寻路系统\n+- **学习内容**：\n+  - D*算法\n+  - D*算法的实现细节\n+  - 实例\n+  - 在游戏中又如何呢?\n+- **应用场景**：\n+  - 动态环境寻路\n+  - 需要频繁重新规划的寻路\n+  - 最小开销重新规划\n+- **Unity工具**：Unity NavMesh（基础支持）、需要自己实现D*算法\n+- **参考价值**：理解动态寻路算法在游戏中的应用\n+\n+## 游戏编程精粹6\n+\n+### 3.2 独立非玩家角色合作行为的实现 ⭐⭐⭐\n+\n+- **项目已有**：可能有基础NPC系统\n+- **掌握程度**：部分掌握，有NPC开发经验，但可以学习NPC合作行为系统\n+- **学习价值**：学习独立非玩家角色合作行为的实现，实现NPC协作系统\n+- **学习内容**：\n+  - 可能的解决方案\n+  - 非玩家角色的结构\n+  - 合作的机制\n+  - 例子:合作寻找玩家\n+- **应用场景**：\n+  - NPC协作系统\n+  - 团队AI行为\n+  - 多NPC协调\n+- **Unity工具**：需要自己实现\n+- **参考价值**：理解NPC合作行为的实现思路\n+\n+### 3.3 针对游戏的基于行为的机器人架构 ⭐⭐⭐\n+\n+- **项目已有**：可能有基础AI系统\n+- **掌握程度**：部分掌握，有AI开发经验，但可以学习基于行为的架构\n+- **学习价值**：学习针对游戏的基于行为的机器人架构，实现行为驱动AI\n+- **学习内容**：\n+  - 包容体结构\n+  - 扩展的行为网络\n+  - 讨论\n+- **应用场景**：\n+  - 行为驱动AI\n+  - 基于行为的机器人\n+  - 行为网络系统\n+- **Unity工具**：需要自己实现\n+- **参考价值**：理解基于行为的AI架构设计\n+\n+### 3.4 使用模糊感知器、有限状态自动机和扩展的行为网络构建目标驱动的机器人 ⭐⭐⭐\n+\n+- **项目已有**：有限状态机（项目已有完整FSM系统）\n+- **掌握程度**：部分掌握，有FSM使用经验，但可以学习模糊感知器+行为网络组合\n+- **学习价值**：学习使用模糊感知器、FSM和扩展的行为网络构建目标驱动的机器人\n+- **学习内容**：\n+  - 扩展的行为网络设计\n+  - 层次模糊感知器\n+  - 有限状态自动机行为模块\n+- **应用场景**：\n+  - 目标驱动AI\n+  - 模糊感知器应用\n+  - 行为网络系统\n+- **Unity工具**：需要自己实现，可以基于现有FSM系统扩展\n+- **参考价值**：理解模糊感知器、FSM和行为网络的组合应用\n+\n+### 3.5 一个目标驱动的虚幻竞技场游戏角色程序 ⭐⭐⭐\n+\n+- **项目已有**：可能有基础AI系统\n+- **掌握程度**：部分掌握，有AI开发经验，但可以学习目标驱动的代理系统\n+- **学习价值**：学习使用扩展的行为网络制作目标驱动的具有个性的代理\n+- **学习内容**：\n+  - 扩展的行为网络\n+  - 行为选择的质量\n+  - 个性设计\n+- **应用场景**：\n+  - 目标驱动AI\n+  - 具有个性的代理\n+  - 行为网络系统\n+- **Unity工具**：需要自己实现\n+- **参考价值**：理解目标驱动代理和个性设计\n+\n+### 3.6 用支持向量机为短期记忆建模 ⭐⭐⭐\n+\n+- **项目已有**：可能有基础AI系统\n+- **掌握程度**：部分掌握，有AI开发经验，但可以学习支持向量机（SVM）应用\n+- **学习价值**：学习用支持向量机为短期记忆建模，实现AI记忆系统\n+- **学习内容**：\n+  - 支持向量机简介\n+  - 短期记忆模型化\n+  - CPU的消耗限制\n+- **应用场景**：\n+  - AI记忆系统\n+  - 短期记忆建模\n+  - 机器学习应用\n+- **Unity工具**：需要自己实现\n+- **参考价值**：理解支持向量机在游戏AI中的应用\n+\n+### 3.7 使用战力值评估模型进行战争役分析 ⭐⭐⭐\n+\n+- **项目已有**：可能有基础战斗系统\n+- **掌握程度**：部分掌握，有战斗系统使用经验，但可以学习战力值评估模型\n+- **学习价值**：学习使用战力值评估模型进行战争役分析，实现战斗评估系统\n+- **学习内容**：\n+  - 基本公式\n+  - 计算兵力\n+  - 计算潜在兵力\n+  - 为武器效力进行建模\n+  - 获得一个理论上的战争结局\n+  - 关于CEV\n+  - 一个QJM系统的例子\n+  - 局限性\n+- **应用场景**：\n+  - 战斗评估系统\n+  - 战争役分析\n+  - 战力值评估\n+- **Unity工具**：需要自己实现\n+- **参考价值**：理解战力值评估模型在游戏中的应用\n+\n+## 游戏编程精粹7\n+\n+### 3.1 用行为克隆创建有趣的代理 ⭐⭐⭐\n+\n+- **项目已有**：可能有基础AI系统\n+- **掌握程度**：部分掌握，有AI开发经验，但可以学习行为克隆技术\n+- **学习价值**：学习用行为克隆创建有趣的代理，实现机器学习驱动的AI\n+- **学习内容**：\n+  - 实例:The Demo Game\n+  - 行为克隆技术\n+  - 机器学习应用\n+- **应用场景**：\n+  - 机器学习驱动的AI\n+  - 行为克隆系统\n+  - 有趣的代理创建\n+- **Unity工具**：\n+  - Unity ML-Agents（机器学习，可能支持行为克隆）\n+  - ⚠️ **需要自己实现**：行为克隆系统\n+- **参考价值**：理解行为克隆在游戏AI中的应用\n+\n+### 3.4 有关态度的一切:为意见、声望和NPC个性构建单元 ⭐⭐⭐\n+\n+- **项目已有**：可能有基础NPC系统\n+- **掌握程度**：部分掌握，有NPC开发经验，但可以学习NPC个性系统\n+- **学习价值**：学习为意见、声望和NPC个性构建单元，实现复杂的NPC个性系统\n+- **学习内容**：\n+  - 简介\n+  - 态度\n+  - 态度里有什么\n+  - 复杂的态度对象\n+  - 态度和行为\n+  - 说服和影响\n+  - 态度的社会交换\n+  - 另一个例子\n+  - 注意事项和结论\n+- **应用场景**：\n+  - NPC个性系统\n+  - 意见和声望系统\n+  - 复杂的态度建模\n+- **Unity工具**：需要自己实现\n+- **参考价值**：理解NPC个性系统在游戏中的应用\n+\n+### 3.6 面向目标的计划合并 ⭐⭐⭐\n+\n+- **项目已有**：可能有基础规划系统\n+- **掌握程度**：部分掌握，有规划系统使用经验，但可以学习目标计划合并\n+- **学习价值**：学习面向目标的计划合并，实现多目标协调规划        ，                                  \n+- **学习内容**：\n+  - 回顾面向目标的计划系统\n+  - 用于面向目标计划的计划合并\n+- **应用场景**：\n+  - 多目标协调规划\n+  - 计划合并系统\n+  - 目标驱动规划\n+- **Unity工具**：需要自己实现\n+- **参考价值**：理解目标计划合并在游戏AI中的应用\n+\n+## 总结\n+\n+**待学习的AI技术**：\n+1. ⭐⭐⭐ **Steering Behaviors**：定向行为系统，AI移动行为基础\n+2. ⭐⭐⭐ **Flocking**：群集行为，群体AI行为\n+3. ⭐⭐⭐ **模糊逻辑**：模糊决策系统\n+4. ⭐⭐⭐ **神经网络**：AI学习系统\n+5. ⭐⭐⭐ **影响力地图**：战略决策系统\n+6. ⭐⭐⭐ **策略评估技术**：资源分配和决策\n+7. ⭐⭐⭐ **地形推理**：战术分析系统\n+8. ⭐⭐⭐ **可视点寻径**：路径优化技术\n+9. ⭐⭐⭐ **区域游览**：寻径模式扩展\n+10. ⭐⭐⭐ **寻径与碰撞**：高级关系处理方法\n+11. ⭐⭐⭐ **NPC决策处理随机问题**：动态规划算法\n+12. ⭐⭐⭐ **基于效用的决策架构**：面向对象决策系统\n+13. ⭐⭐⭐ **分布式推理投票架构**：多系统协作决策\n+14. ⭐⭐⭐ **吸引子和排斥子**：自然移动系统\n+15. ⭐⭐⭐ **RTS造墙算法**：智能建筑系统\n+16. ⭐⭐⭐ **人工势场**：快速目标评级系统\n+17. ⭐⭐⭐ **Lanchester损耗模型**：战斗结果预测系统\n+18. ⭐⭐⭐ **智能规划系统**：长期目标规划系统\n+19. ⭐⭐⭐ **动态A*(D*)算法**：最小重新规划开销的寻路算法\n+20. ⭐⭐⭐ **NPC合作行为**：独立非玩家角色合作行为的实现\n+21. ⭐⭐⭐ **基于行为的架构**：针对游戏的基于行为的机器人架构\n+22. ⭐⭐⭐ **模糊感知器+行为网络**：目标驱动的机器人构建\n+23. ⭐⭐⭐ **目标驱动代理**：具有个性的目标驱动代理\n+24. ⭐⭐⭐ **支持向量机**：用支持向量机为短期记忆建模\n+25. ⭐⭐⭐ **战力值评估模型**：使用战力值评估模型进行战争役分析\n+26. ⭐⭐⭐ **行为克隆**：用行为克隆创建有趣的代理\n+27. ⭐⭐⭐ **NPC个性系统**：为意见、声望和NPC个性构建单元\n+28. ⭐⭐⭐ **目标计划合并**：面向目标的计划合并\n+\n+**学习建议**：\n+- 按需学习，根据项目需求决定是否实现\n+- 可以基于现有系统（网格系统、寻路系统）实现\n+- 参考代码示例，理解原理后实现\n+\n"
                },
                {
                    "date": 1765979929631,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -1,7 +1,7 @@\n # 待学习AI技术（⭐⭐⭐）\n \n-> 本文档整合了《游戏编程精粹》第1-7卷中项目部分掌握需要补充完善的AI技术。\n+> 本文档整合了《游戏编程精粹》第1-8卷中项目部分掌握需要补充完善的AI技术。\n \n ## 游戏编程精粹1\n \n ### 5. Steering Behaviors（定向行为系统） ⭐⭐⭐\n@@ -549,9 +549,130 @@\n 25. ⭐⭐⭐ **战力值评估模型**：使用战力值评估模型进行战争役分析\n 26. ⭐⭐⭐ **行为克隆**：用行为克隆创建有趣的代理\n 27. ⭐⭐⭐ **NPC个性系统**：为意见、声望和NPC个性构建单元\n 28. ⭐⭐⭐ **目标计划合并**：面向目标的计划合并\n+29. ⭐⭐⭐ **自动导航网格生成**：使用高级增长技术的自动导航网格生成\n+30. ⭐⭐⭐ **控制理论应用**：将控制理论应用于游戏AI和物理\n+31. ⭐⭐⭐ **自适应战术选择**：第一人称射击游戏中的自适应战术选择\n+32. ⭐⭐⭐ **混沌理论**：通过确定性系统生成明显的不可预测性\n+33. ⭐⭐⭐ **基于需求的AI**：需求驱动的AI系统设计\n+34. ⭐⭐⭐ **情感数字角色框架**：情感数字角色框架设计\n+35. ⭐⭐⭐ **可扩展对话创作**：可扩展对话创作系统\n \n+## 游戏编程精粹8（游戏编程精粹4）\n+\n+### 3.3 Automated Navigation Mesh Generation Using Advanced Growth-Based Techniques（使用高级增长技术的自动导航网格生成） ⭐⭐⭐\n+\n+- **项目已有**：Unity NavMesh导航系统\n+- **掌握程度**：部分掌握，有NavMesh使用经验，但可以学习自动生成原理\n+- **学习价值**：学习导航网格的自动生成算法，理解NavMesh背后的原理\n+- **学习内容**：\n+  - 导航网格自动生成算法\n+  - 增长技术（Growth-Based Techniques）\n+  - 网格生成优化\n+- **应用场景**：\n+  - 理解Unity NavMesh原理\n+  - 自定义导航网格生成\n+  - 动态环境导航网格更新\n+- **Unity工具**：Unity NavMesh已封装，但可以学习原理\n+- **参考价值**：理解导航网格生成的底层原理\n+\n+### 3.5 Applying Control Theory to Game AI and Physics（将控制理论应用于游戏AI和物理） ⭐⭐⭐\n+\n+- **项目已有**：可能有物理系统、AI系统\n+- **掌握程度**：部分掌握，有物理和AI使用经验，但可以学习控制理论应用\n+- **学习价值**：学习如何将控制理论应用于游戏AI和物理系统\n+- **学习内容**：\n+  - 控制理论基础\n+  - AI中的控制理论应用\n+  - 物理系统中的控制理论\n+- **应用场景**：\n+  - AI控制系统\n+  - 物理模拟优化\n+  - 精确控制需求\n+- **Unity工具**：需要自己实现\n+- **参考价值**：理解控制理论在游戏开发中的应用\n+\n+### 3.6 Adaptive Tactic Selection in First-Person Shooter (FPS) Games（第一人称射击游戏中的自适应战术选择） ⭐⭐⭐\n+\n+- **项目已有**：可能有AI决策系统\n+- **掌握程度**：部分掌握，有AI决策经验，但可以学习自适应战术选择\n+- **学习价值**：学习如何在FPS游戏中实现自适应战术选择系统\n+- **学习内容**：\n+  - 自适应战术选择算法\n+  - FPS游戏AI战术系统\n+  - 动态战术调整\n+- **应用场景**：\n+  - FPS游戏AI\n+  - 战术决策系统\n+  - 自适应AI行为\n+- **Unity工具**：需要自己实现\n+- **参考价值**：理解自适应战术选择在FPS游戏中的应用\n+\n+### 3.7 Embracing Chaos Theory: Generating Apparent Unpredictability through Deterministic Systems（拥抱混沌理论：通过确定性系统生成明显的不可预测性） ⭐⭐⭐\n+\n+- **项目已有**：可能有随机数系统\n+- **掌握程度**：部分掌握，有随机数使用经验，但可以学习混沌理论应用\n+- **学习价值**：学习如何使用混沌理论生成看似随机但确定的行为\n+- **学习内容**：\n+  - 混沌理论基础\n+  - 确定性系统设计\n+  - 不可预测性生成\n+- **应用场景**：\n+  - 看似随机但可重现的AI行为\n+  - 复杂系统模拟\n+  - 自然行为生成\n+- **Unity工具**：需要自己实现\n+- **参考价值**：理解混沌理论在游戏AI中的应用\n+\n+### 3.8 Needs-Based AI（基于需求的AI） ⭐⭐⭐\n+\n+- **项目已有**：可能有AI决策系统\n+- **掌握程度**：部分掌握，有AI决策经验，但可以学习基于需求的AI系统\n+- **学习价值**：学习如何设计基于需求的AI系统，实现更自然的AI行为\n+- **学习内容**：\n+  - 需求系统设计\n+  - 基于需求的决策\n+  - AI行为驱动机制\n+- **应用场景**：\n+  - 自然AI行为\n+  - 需求驱动决策\n+  - 复杂AI系统\n+- **Unity工具**：需要自己实现\n+- **参考价值**：理解基于需求的AI系统设计\n+\n+### 3.9 A Framework for Emotional Digital Actors（情感数字角色框架） ⭐⭐⭐\n+\n+- **项目已有**：可能有AI系统、动画系统\n+- **掌握程度**：部分掌握，有AI和动画使用经验，但可以学习情感系统\n+- **学习价值**：学习如何设计情感数字角色框架，实现有情感的AI角色\n+- **学习内容**：\n+  - 情感系统设计\n+  - 数字角色情感表达\n+  - 情感驱动行为\n+- **应用场景**：\n+  - 情感AI角色\n+  - 角色情感表达\n+  - 复杂角色系统\n+- **Unity工具**：需要自己实现\n+- **参考价值**：理解情感系统在数字角色中的应用\n+\n+### 3.10 Scalable Dialog Authoring（可扩展对话创作） ⭐⭐⭐\n+\n+- **项目已有**：可能有对话系统\n+- **掌握程度**：部分掌握，有对话系统使用经验，但可以学习可扩展对话创作\n+- **学习价值**：学习如何设计可扩展的对话创作系统\n+- **学习内容**：\n+  - 对话系统架构\n+  - 可扩展对话设计\n+  - 对话创作工具\n+- **应用场景**：\n+  - 大型对话系统\n+  - 可扩展对话管理\n+  - 对话创作工具开发\n+- **Unity工具**：需要自己实现\n+- **参考价值**：理解可扩展对话系统的设计\n+\n **学习建议**：\n - 按需学习，根据项目需求决定是否实现\n - 可以基于现有系统（网格系统、寻路系统）实现\n - 参考代码示例，理解原理后实现\n"
                }
            ],
            "date": 1765967845606,
            "name": "Commit-0",
            "content": "# 待学习AI技术（⭐⭐⭐）\r\n\r\n> 本文档整合了《游戏编程精粹》第1-7卷中项目部分掌握需要补充完善的AI技术。\r\n\r\n## 游戏编程精粹1\r\n\r\n### 5. Steering Behaviors（定向行为系统） ⭐⭐⭐\r\n\r\n- **项目已有**：可能有基础移动系统\r\n- **掌握程度**：部分掌握，有移动系统使用经验，但可以学习Steering Behaviors系统\r\n- **学习价值**：学习Reynolds提出的基础行为系统，实现各种移动行为\r\n- **学习内容**：\r\n  - Seek（寻找目标）\r\n  - Flee（逃离目标）\r\n  - Arrive（到达目标，带减速）\r\n  - Pursue（追逐移动目标）\r\n  - Evade（躲避移动目标）\r\n  - Align（对齐朝向）\r\n  - VelocityMatch（速度匹配）\r\n  - Wander（漫游）\r\n  - AvoidWall/AvoidAgent（避障）\r\n- **应用场景**：\r\n  - AI移动行为\r\n  - 群体行为基础\r\n  - 动态避障系统\r\n- **Unity工具**：需要自己实现\r\n- **参考代码**：`ReadNote/游戏编程精粹/1/代码/SteeringBehaviors(定向行为系统).md`\r\n\r\n### 5. Flocking（群集行为） ⭐⭐⭐\r\n\r\n- **项目已有**：可能有基础移动系统\r\n- **掌握程度**：部分掌握，有移动系统使用经验，但可以学习Flocking群集行为\r\n- **学习价值**：学习Craig Reynolds提出的分布式行为模型，模拟鸟群、鱼群等生物群体行为\r\n- **学习内容**：\r\n  - 四个基本规则（Reynolds规则）：\r\n    1. 分离（Separation）：避免与邻近个体过于接近\r\n    2. 对齐（Alignment）：与邻近个体的平均航向和速度对齐\r\n    3. 聚集（Cohesion）：向邻近个体的平均位置移动\r\n    4. 躲避（Avoidance）：避免撞上局部区域内的障碍或敌人\r\n  - 无状态特性\r\n  - 矢量累积机制\r\n  - 性能优化（空间分区、邻居限制）\r\n- **应用场景**：\r\n  - 群体AI行为\r\n  - 鸟群、鱼群模拟\r\n  - RTS/RPG中的群体动画\r\n- **Unity工具**：需要自己实现\r\n- **参考代码**：`ReadNote/游戏编程精粹/1/代码/Flocking群集行为.md`\r\n\r\n### 5. 模糊逻辑（Fuzzy Logic） ⭐⭐⭐\r\n\r\n- **项目已有**：可能有基础决策系统\r\n- **掌握程度**：部分掌握，有决策系统使用经验，但可以学习模糊逻辑决策系统\r\n- **学习价值**：学习处理不确定性和模糊性的数学方法，实现平滑的AI决策\r\n- **学习内容**：\r\n  - 模糊集合和隶属度函数\r\n  - 模糊推理（Fuzzy Inference）：\r\n    1. 模糊化（Fuzzification）\r\n    2. 规则评估（Rule Evaluation）\r\n    3. 聚合（Aggregation）\r\n    4. 去模糊化（Defuzzification）\r\n  - 典型隶属度函数（三角形、梯形、S形）\r\n  - 模糊逻辑运算（AND、OR、NOT）\r\n- **应用场景**：\r\n  - AI决策系统\r\n  - NPC行为选择\r\n  - 难度调整\r\n  - 资源管理\r\n- **Unity工具**：需要自己实现\r\n- **参考代码**：`ReadNote/游戏编程精粹/1/代码/模糊逻辑(FuzzyLogic).md`\r\n\r\n### 5. 神经网络（Neural Networks） ⭐⭐⭐\r\n\r\n- **项目已有**：可能有基础AI系统\r\n- **掌握程度**：部分掌握，有AI开发经验，但可以学习神经网络系统\r\n- **学习价值**：学习模拟生物神经系统的计算模型，实现复杂的非线性映射\r\n- **学习内容**：\r\n  - 神经单元（Neuron）结构\r\n  - 激活函数（Sigmoid、ReLU、Tanh）\r\n  - 多层神经网络\r\n  - Hebbian学习规则\r\n  - 前向传播和反向传播\r\n- **应用场景**：\r\n  - AI决策\r\n  - 行为预测\r\n  - 难度调整\r\n  - NPC行为学习\r\n- **Unity工具**：Unity ML-Agents（机器学习）、需要自己实现基础神经网络\r\n- **参考代码**：`ReadNote/游戏编程精粹/1/代码/神经网络(Neural Networks).md`\r\n\r\n### 5. 影响力地图（Influence Map） ⭐⭐⭐\r\n\r\n- **项目已有**：可能有基础网格系统（GridSystem）\r\n- **掌握程度**：部分掌握，有网格系统使用经验，但可以学习影响力地图系统\r\n- **学习价值**：学习用于AI决策的地图系统，表示地图上各区域的重要性\r\n- **学习内容**：\r\n  - 影响力传播算法\r\n  - 合意值计算（Desirability）\r\n  - 地形考虑\r\n  - 3D环境应用\r\n  - 影响力衰减（线性衰减或指数衰减）\r\n- **应用场景**：\r\n  - RTS游戏中的战略决策\r\n  - 单位部署\r\n  - 资源点选择\r\n  - 战术位置评估\r\n- **Unity工具**：需要自己实现，可以基于现有的网格系统和范围查找策略实现\r\n- **参考代码**：`ReadNote/游戏编程精粹/1/代码/影响力地图(InfluenceMap).md`\r\n\r\n### 5. 策略评估技术 ⭐⭐⭐\r\n\r\n- **项目已有**：可能有基础决策系统\r\n- **掌握程度**：部分掌握，有决策系统使用经验，但可以学习策略评估技术\r\n- **学习价值**：学习资源分配树、依存图等策略评估技术\r\n- **学习内容**：\r\n  - 资源分配树\r\n  - 依存图\r\n  - 策略决策\r\n  - 经济规划\r\n- **应用场景**：\r\n  - RTS游戏的经济规划\r\n  - 资源分配\r\n  - 策略类游戏\r\n- **Unity工具**：需要自己实现\r\n- **参考代码**：`ReadNote/游戏编程精粹/1/代码/策略评估技术(StrategyEvaluation).md`\r\n\r\n### 5. 地形推理 ⭐⭐⭐\r\n\r\n- **项目已有**：可能有基础地形系统（EBattleTerrain地形类型枚举）\r\n- **掌握程度**：部分掌握，有地形使用经验，但可以学习地形推理技术\r\n- **学习价值**：学习中继点（Waypoint）、战术分析等地形推理技术\r\n- **学习内容**：\r\n  - 中继点系统\r\n  - 战术分析\r\n  - 地形表示\r\n  - 从经验中学习\r\n- **应用场景**：\r\n  - 战术位置评估\r\n  - 防御点识别\r\n  - 进攻路线规划\r\n- **Unity工具**：Unity NavMesh（基础支持）、需要自己实现高级功能\r\n- **参考代码**：`ReadNote/游戏编程精粹/1/代码/地形推理(TerrainReasoning).md`\r\n\r\n### 5. 可视点寻径（Points-of-Visibility Pathfinding） ⭐⭐⭐\r\n\r\n- **项目已有**：A*寻路算法实现\r\n- **掌握程度**：部分掌握，有A*寻路经验，但可以学习可视点寻径优化技术\r\n- **学习价值**：学习可视点寻径优化技术，用于优化路径查找\r\n- **学习内容**：\r\n  - 可视点寻径算法\r\n  - 存储到每个点的最短路径\r\n  - 轮廓区\r\n  - 空间分区系统\r\n- **应用场景**：\r\n  - 路径优化\r\n  - 大规模寻径系统\r\n  - 作为A*算法的优化技术\r\n- **Unity工具**：Unity NavMesh（基础支持）、需要自己实现高级优化\r\n- **参考代码**：`ReadNote/游戏编程精粹/1/代码/可视点寻径(PointsOfVisibility).md`\r\n\r\n## 游戏编程精粹3\r\n\r\n### 3.9 区域游览（寻径模式扩展） ⭐⭐⭐\r\n\r\n- **项目已有**：A*寻路算法实现和Unity NavMesh系统\r\n- **掌握程度**：部分掌握，有基础寻径经验，但可以学习区域游览模式\r\n- **学习价值**：学习寻径模式扩展，实现区域游览功能\r\n- **学习内容**：\r\n  - 区域游览的概念\r\n  - 寻径模式扩展\r\n  - 区域识别和遍历\r\n- **应用场景**：\r\n  - 巡逻系统\r\n  - 区域探索\r\n  - 寻径模式扩展\r\n- **Unity工具**：Unity NavMesh（基础支持）、需要自己实现区域游览\r\n\r\n### 3.8 在寻径与碰撞之间选择一种关系（高级方法） ⭐⭐⭐\r\n\r\n- **项目已有**：Unity NavMesh系统和物理碰撞系统\r\n- **掌握程度**：部分掌握，有基础寻径与碰撞经验，但可以学习三种关系处理方法\r\n- **学习价值**：学习寻径与碰撞的三种关系处理方法，实现更精确的移动控制\r\n- **学习内容**：\r\n  - 方法1：具有容错性的AI（容错寻径）\r\n  - 方法2：在无障碍空间一个子集内的寻径（受限寻径）\r\n  - 方法3：使用寻径器本身处理人物碰撞（寻径器碰撞处理）\r\n- **应用场景**：\r\n  - 需要精确碰撞控制的游戏\r\n  - 多单位密集移动场景\r\n  - 需要容错性的AI系统\r\n- **Unity工具**：Unity NavMesh + Physics（基础支持）、需要自己实现高级方法\r\n\r\n## 总结\r\n\r\n**待学习的AI技术**：\r\n1. ⭐⭐⭐ **Steering Behaviors**：定向行为系统，AI移动行为基础\r\n2. ⭐⭐⭐ **Flocking**：群集行为，群体AI行为\r\n3. ⭐⭐⭐ **模糊逻辑**：模糊决策系统\r\n4. ⭐⭐⭐ **神经网络**：AI学习系统\r\n5. ⭐⭐⭐ **影响力地图**：战略决策系统\r\n6. ⭐⭐⭐ **策略评估技术**：资源分配和决策\r\n7. ⭐⭐⭐ **地形推理**：战术分析系统\r\n8. ⭐⭐⭐ **可视点寻径**：路径优化技术\r\n9. ⭐⭐⭐ **区域游览**：寻径模式扩展\r\n10. ⭐⭐⭐ **寻径与碰撞**：高级关系处理方法\r\n\r\n**学习建议**：\r\n- 按需学习，根据项目需求决定是否实现\r\n- 可以基于现有系统（网格系统、寻路系统）实现\r\n- 参考代码示例，理解原理后实现\r\n\r\n"
        }
    ]
}